{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "import prettytable\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "    \n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if null_threshold * total / 100 < data[col].isnull().sum():\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.apply(pd.to_numeric,errors='coerce')\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    \"\"\"\n",
    "    Removes all the Next Day columns.\n",
    "    Removes all the non Growth Rate Columns (GR)\n",
    "    add the predictor column to list of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    column : string\n",
    "        name of the predictor column \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    column : string\n",
    "        name of the predictor column\n",
    "    \"\"\"\n",
    "    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list()\n",
    "\n",
    "def get_combinations(arr):\n",
    "    n = len(arr)\n",
    "    indices = [0 for i in range(n)]\n",
    "    while (1):\n",
    "        res = list()\n",
    "        for i in range(n):\n",
    "            res.append(arr[i][indices[i]])\n",
    "        combinations.append(res)\n",
    "        next = n - 1\n",
    "        while (next >= 0 and\n",
    "              (indices[next] + 1 >= len(arr[next]))):\n",
    "            next-=1\n",
    "        if (next < 0):\n",
    "            return\n",
    "        indices[next] += 1\n",
    "        for i in range(next + 1, n):\n",
    "            indices[i] = 0\n",
    "u = [25,75,50,100]\n",
    "b = [25,32,48,64]\n",
    "e = [25,50,75,100]\n",
    "arr = [u,b,e]\n",
    "get_combinations(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(X_train,layers=3,units = 32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=units,input_dim=(X_train.shape[1]),activation = 'relu'))\n",
    "    model.add(Dense(units=units,activation = 'relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     for i in range(layers):\n",
    "#         model.add(Dense(units=units,activation = 'relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 1,activation = 'relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropogation(X,Y,layers = 3,epochs = 5, batch_size = 32,units=50):\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state = 0)\n",
    "    model = create_model(x_train,layers,units)\n",
    "    model.compile(loss=\"mse\", optimizer=\"Adam\", metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size=100, epochs=30, validation_data = (x_test, y_test),shuffle = False,verbose=0)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "    c = 0\n",
    "    for a,b in zip(y_pred,y_test):\n",
    "        if a * b >= 0:\n",
    "            c += 1\n",
    "    direction = c/len(y_test)\n",
    "    \n",
    "    myres =  {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"rsquared_adj\":r2}\n",
    "    myres.update({\"units\":units,\"epochs\":epochs,\"batch_size\":batch_size,\"direction\":direction})\n",
    "    print(\"done\")\n",
    "    return myres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock\")):\n",
    "    if (filename.startswith(\"gr\")):\n",
    "        df = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\" + filename))\n",
    "        column = \"Next Day Close Price GR\"\n",
    "        df = pre_process_data(df,60)\n",
    "        (df,column) = dependent_column(df,column)\n",
    "        X = df[df.columns[:-1]]\n",
    "        Y = df[column]\n",
    "        arguments = list()\n",
    "        for units,batch_size,epochs in combinations:\n",
    "            data = [X,Y,layers,epochs,batch_size,units]\n",
    "            arguments.append(data)\n",
    "        threads = ThreadPool(4)\n",
    "        result = threads.starmap(backpropogation,arguments)\n",
    "        resultdf = pd.DataFrame(result)\n",
    "        resultdf.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models Results\\\\\" + filename[2:8] + \"_bpnn_regression\"  + \".csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models Results'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(),\"Data\\\\Models Results\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {\"500112\" : \"SBIN\" ,\n",
    "\"500325\" : \"RELIANCE INDUSTRIES LTD\",\n",
    "\"532540\" : \"TATA CONSULTANCY SERVICES LTD\" ,\n",
    "\"500209\" : \"INFOSYS LTD\", \n",
    "\"532174\" : \"ICICI BANK LTD\", \n",
    "\"507685\" : \"WIPRO LTD\", \n",
    "\"530965\" : \"INDIAN OIL CORPORATION LTD\", \n",
    "\"500182\" : \"HERO MOTOCORP LTD\", \n",
    "\"532210\" : \"CITY UNION BANK LTD\", \n",
    "\"500180\" : \"HDFC Bank Ltd\",\n",
    "\"500680\" : \"PFIZER LTD\", \n",
    "\"506395\" : \"COROMANDEL iNTERNATIONAL LTD\",\n",
    "\"500770\" : \"TATA CHEMICALS LTD\", \n",
    "\"500085\" : \"CHAMBAL FERTILISERS & CHEMICALS LTD\", \n",
    "\"501425\" : \"BOMBAY BURMAH TRADING CORP.LTD\", \n",
    "\"532899\" : \"KAVERI SEED COMPANY LTD\", \n",
    "\"537291\" : \"NATH BIO-GENES (INDIA) LTD\", \n",
    "\"500790\" : \"NESTLE INDIA LTD\", \n",
    "\"500825\" : \"BRITANNIA INDUSTRIES LTD\", \n",
    "\"533155\" : \"JUBILANT FOODWORKS LTD\", \n",
    "\"533287\" : \"ZEE LEARN LTD\", \n",
    "\"533260\" : \"CAREER POINT LTD\", \n",
    "\"539921\" : \"SHANTI EDUCATIONAL INITIATIVES LTD\", \n",
    "\"542602\" : \"EMBASSY OFFICE PARKS REIT\", \n",
    "\"543217\" : \"MINDSPACE BUSINESS PARKS REIT\", \n",
    "\"543261\" : \"BROOKFIELD INDIA REAL ESTATE TRUST REIT\", \n",
    "\"532538\" : \"ULTRATECH CEMENT LTD\", \n",
    "\"500387\" : \"SHREE CEMENT LTD\", \n",
    "\"500425\" : \"AMBUJA CEMENTS LTD\", \n",
    "\"532689\" : \"PVR LTD\", \n",
    "\"532706\" : \"INOX LEISURE LTD\", \n",
    "\"532163\" : \"SAREGAMA INDIA LTD\", \n",
    "\"524715\" : \"SUN PHARMACEUTICAL INDUSTRIES LTD\", \n",
    "\"532488\" : \"DIVI'S LABORATORIES LTD\",\n",
    "\"500124\" : \"DR.REDDY'S LABORATORIES LTD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bpnn = pd.DataFrame()\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\"_bpnn_regression.csv\") and \"final\" not in filename:\n",
    "        df = pd.read_csv(os.path.join(path,filename))\n",
    "        table = prettytable.PrettyTable()\n",
    "        table.field_names = df.columns\n",
    "        table.title = str(filename[:6]) + \"-bpnn_regression\"\n",
    "        for _,row in df.iterrows():\n",
    "            row = [round(r,6) for r in row]\n",
    "            table.add_row(row)\n",
    "        df[\"Company\"] = str(filename[:6]) + \"-\" + companies(str(filename[:6]))\n",
    "        print(table)\n",
    "        best_bpnn = best_bpnn.append(df.sort_values(by=[\"direction\"],ascending=[False]).head(1),ignore_index=True)\n",
    "best_bpnn.to_csv(os.path.join(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models Results\\\\\" + filename[:6] + \"final_bpnn_regression\"+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "besttable = prettytable.PrettyTable()\n",
    "besttable.field_names = df.columns\n",
    "besttable.title = \"best\" + \" bpnn\"\n",
    "for _,row in best_bpnn.iterrows():\n",
    "    row = [round(r,6) if isinstance(r,(int,float)) else r for r in row]\n",
    "    besttable.add_row(row)\n",
    "print(besttable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
