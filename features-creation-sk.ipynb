{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import calendar\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/kaggle/input/newdata\"\n",
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Drops the duplicate rows in the dataframe based on Date column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    df: dataframe\n",
    "        updated dataframe after droping duplicates.\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates(subset=[\"Date\"],keep=\"first\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_previous_values(df):\n",
    "    \"\"\"\n",
    "    Fills the null values in the dataframe with the values from the previous row.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    df : dataframe\n",
    "        updated dataframe after filling with previous values.\n",
    "        \n",
    "    \"\"\"\n",
    "    df.fillna(method=\"ffill\",inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(df,ind):\n",
    "    \"\"\"\n",
    "\n",
    "    Adds rows to the stock dataframe.\n",
    "\n",
    "    If the date is present in index dataframe an not present in stock dataframe,\n",
    "    then a new row (as date and NAN values) is added to stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    df : dataframe\n",
    "        stock dataframe\n",
    "    \n",
    "    ind : dataframe\n",
    "        index dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    df : dataframe\n",
    "        updated dataframe after adding new rows.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    ind.Date = pd.to_datetime(ind.Date)\n",
    "    s = df.Date.head(1).values[0]\n",
    "    e = df.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    missing_df = pd.DataFrame(columns=df.columns)\n",
    "    indexes_dates = ind.Date.values\n",
    "    df.Date = pd.to_datetime(df.Date)\n",
    "    df_dates = df.Date.values\n",
    "    start = 0\n",
    "    for i,v in enumerate(indexes_dates):\n",
    "        if v not in df.Date.values:\n",
    "            m = abs(ind.shape[1]-missing_df.shape[1])\n",
    "            res = list(np.append(ind.iloc[i].values,[np.nan]*m))\n",
    "            missing_df.loc[start] = res\n",
    "            start += 1\n",
    "    df = pd.concat([df,missing_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df,ind):\n",
    "    \"\"\"\n",
    "    Removes duplicate rows, Adds missing rows, fills null values from pervious row to the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : dataframe\n",
    "        stock dataframe\n",
    "    \n",
    "    ind : dataframe\n",
    "        index dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    df : dataframe\n",
    "        updated dataframe after performing all the operations.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df = drop_duplicate_rows(df)\n",
    "    ind = drop_duplicate_rows(ind)\n",
    "    df = add_missing_rows(df,ind)\n",
    "    df = fill_with_previous_values(df)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = drop_duplicate_rows(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Corporate Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_issue(stock,start_date,end_date,r1,r2):\n",
    "    \"\"\"\n",
    "    For an r1:r2 bonus shares,\n",
    "    if y is the stock value before the bonus share issue,\n",
    "    then the value of the stock will be y*(r2/(r1+r2)),\n",
    "    for the data between the given dates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    start_date : datetime\n",
    "    \n",
    "    end_date : datetime\n",
    "\n",
    "    r1 : integer\n",
    "\n",
    "    r2 : integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe after bonus\n",
    "    \"\"\"\n",
    "    specific_dates = stock[stock.Date.between(end_date,start_date)]\n",
    "    for index,row in specific_dates.iterrows():\n",
    "        specific_dates.loc[index,\"Open Price\"] = specific_dates.loc[index,\"Open Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"Low Price\"] = specific_dates.loc[index,\"Low Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"High Price\"] = specific_dates.loc[index,\"High Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"Close Price\"] = specific_dates.loc[index,\"Close Price\"] * (r2/(r1+r2))\n",
    "        specific_dates.loc[index,\"WAP\"] = specific_dates.loc[index,\"WAP\"] * (r2/(r1+r2))\n",
    "        stock.loc[index] = specific_dates.loc[index]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_split(stock,start_date,end_date,r1,r2):\n",
    "    \"\"\"\n",
    "    For an r1:r2 stock split, if y is the stock value before the split,\n",
    "    then the value of the stock will be y*(r1/r2),\n",
    "    for the data between the given dates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    start_date : datetime\n",
    "    \n",
    "    end_date : datetime\n",
    "\n",
    "    r1 : integer\n",
    "\n",
    "    r2 : integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe after splitting\n",
    "    \"\"\"\n",
    "    start_date = start_date - timedelta(days = 1)\n",
    "    print(start_date, end_date)\n",
    "    specific_dates = stock[stock.Date.between(end_date,start_date)]\n",
    "    for index,row in specific_dates.iterrows():\n",
    "        specific_dates.loc[index,\"Open Price\"] = specific_dates.loc[index,\"Open Price\"] * (r2/r1)\n",
    "        specific_dates.loc[index,\"Low Price\"] = specific_dates.loc[index,\"Low Price\"] * (r2/r1)\n",
    "        specific_dates.loc[index,\"High Price\"] = specific_dates.loc[index,\"High Price\"] * (r2/r1)\n",
    "        specific_dates.loc[index,\"Close Price\"] = specific_dates.loc[index,\"Close Price\"] * (r2/r1)\n",
    "        specific_dates.loc[index,\"WAP\"] = specific_dates.loc[index,\"WAP\"] * (r2/r1)\n",
    "        try:\n",
    "            stock.loc[index] = specific_dates.loc[index]\n",
    "        except:\n",
    "#             print(stock.loc[index])\n",
    "#             print(specific_dates.loc[index])\n",
    "            continue\n",
    "            \n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dividend(stock,corporate):\n",
    "    \"\"\"\n",
    "    Creates new Dividend Value column in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    corporate : dataframe\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with dividend column\n",
    "    \n",
    "    \"\"\"\n",
    "    corporate['Ex Date'] = pd.to_datetime(corporate['Ex Date'], errors='coerce')\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
    "\n",
    "    dividend = corporate[corporate['Purpose'].str.contains(\"Dividend\")]\n",
    "    result = {}\n",
    "    for index,row in dividend.iterrows():\n",
    "        year = row[\"Ex Date\"].year\n",
    "        month = row[\"Ex Date\"].month\n",
    "        amount = re.findall(r\"\\d+.?\\d*\",row[\"Purpose\"])[0]\n",
    "        res = result.get(year,{})\n",
    "        q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "        val = res.get(q,[])\n",
    "        val.append(float(amount))\n",
    "        res[q] = val\n",
    "        result[year] = res\n",
    "    for year,quaters in result.items():\n",
    "        for q, a in quaters.items():\n",
    "            quaters[q] = sum(a)/len(a)\n",
    "        result[year] = quaters\n",
    "    divList = list()\n",
    "    for index,row in stock.iterrows():\n",
    "        year = row[\"Date\"].year\n",
    "        month = row[\"Date\"].month\n",
    "        q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "        if result.get(year) != None:\n",
    "            if result.get(year).get(q) != None:\n",
    "                divList.append(result.get(year).get(q))\n",
    "            else:\n",
    "                divList.append(0)\n",
    "        else:\n",
    "            divList.append(0)\n",
    "    stock[\"Dividend Value\"] = divList\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_corporate_actions(stock,corporate):\n",
    "    \"\"\"\n",
    "    Applies stock split and bonus on the given stock dataset.\n",
    "\n",
    "    creates bonus dataframe and invoke bonus_issue method.\n",
    "\n",
    "    creates split dataframe and invoke stock_split method.\n",
    "\n",
    "    creates dividend value Column in Stock dataframe by invoking create_dividend method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "    \n",
    "    corporate : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe after stock split and bonus and dividend.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    stock_split : \n",
    "\n",
    "    bonus_issue :\n",
    "\n",
    "    \"\"\"\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    corporate[\"Ex Date\"] = pd.to_datetime(corporate[\"Ex Date\"],errors='coerce')\n",
    "    # corporate[\"BC Start Date\"] = pd.to_datetime(corporate[\"BC Start Date\"],errors='coerce')\n",
    "    # corporate[\" BC End Date\\t\"] = pd.to_datetime(corporate[\" BC End Date\\t\"],errors='coerce')\n",
    "    # corporate[\"ND Start Date\"] = pd.to_datetime(corporate[\"ND Start Date\"],errors='coerce')\n",
    "    # corporate[\"ND End Date\"] = pd.to_datetime(corporate[\"ND End Date\"],errors='coerce')\n",
    "    \n",
    "    bonus_df = corporate[corporate['Purpose'].str.contains(\"Bonus\")]\n",
    "    for index,row in bonus_df.iterrows():\n",
    "        start_date = bonus_df.loc[index,\"Ex Date\"]\n",
    "        ratio = bonus_df.loc[index,\"Purpose\"]\n",
    "        r1,r2 = re.findall(r\"\\d+\",ratio)\n",
    "        r1,r2 = int(r1),int(r2)\n",
    "        end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "        stock = bonus_issue(stock,start_date,end_date,r1,r2)\n",
    "\n",
    "    stock_split_df = corporate[corporate['Purpose'].str.contains(\"Stock\")]\n",
    "    for index,row in stock_split_df.iterrows():\n",
    "        start_date = stock_split_df.loc[index,\"Ex Date\"]\n",
    "        ratio = stock_split_df.loc[index,\"Purpose\"]\n",
    "        r1,r2 = re.findall(r\"\\d+\",ratio)\n",
    "        r1,r2 = int(r1),int(r2)\n",
    "        end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "        stock = stock_split(stock,start_date,end_date,r1,r2)\n",
    "    \n",
    "    stock = create_dividend(stock,corporate)\n",
    "\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(outputpath):\n",
    "    \"\"\"\n",
    "    creates a new index file with two new columns (%YTD and %Return)\n",
    "    \"\"\"\n",
    "    \n",
    "    ind = pd.read_csv(os.path.join(path,\"Data//Index.csv\"))\n",
    "    ind[\"% Return\"] = ((ind[\"Close\"] / ind['Close'].shift(1))-1)*100\n",
    "    ind[\"% YTD\"] = ((ind.tail(1)['Close'].values[0]/ind[\"Close\"])-1)*100\n",
    "    ind.to_csv(os.path.join(outputpath,\"modIndex.csv\"),index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Beta Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(stock):\n",
    "    \"\"\"\n",
    "\n",
    "    Creates a new Beta column in the stock dataframe\n",
    "\n",
    "    beta = covariance(X, Y)/var(Y)\n",
    "\n",
    "    X = %returns of company\n",
    "    \n",
    "    Y = %returns of sp500\n",
    "\n",
    "    %returns of company = ((Close Price of today / Close Price of previous trading day) - 1) * 100\n",
    "\n",
    "    %returns of sp500 = from new Index dataframe. (% Return)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with new Beta column\n",
    "    \"\"\"\n",
    "    path = os.getcwd()\n",
    "    \n",
    "    stock[\"% Return of Company\"] = ((stock[\"Close Price\"] / stock['Close Price'].shift(1))-1)*100\n",
    "    ind = pd.read_csv(os.path.join(outputpath,\"modIndex.csv\"))\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    s = stock.Date.head(1).values[0]\n",
    "    e = stock.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    ind.rename(columns={'Close':'Close Price of SP500', '% Return':'% Return of SP500'}, inplace=True)\n",
    "    ind.drop(['Open', 'High', 'Low', '% YTD'], axis = 1,inplace=True) \n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    stock = pd.merge(stock, ind, on=\"Date\", how = \"left\")\n",
    "\n",
    "    sp500 = stock[\"% Return of SP500\"]\n",
    "    company = stock[\"% Return of Company\"]\n",
    "    results = list()\n",
    "    for i in range(stock.shape[0]):\n",
    "        # cov = np.cov(company[i:],sp500[i:])[0][1]\n",
    "        cov = np.ma.cov(np.ma.masked_invalid(np.array(company[i:],sp500[i:])),rowvar=False)\n",
    "        var = np.nanvar(sp500[i:])\n",
    "        res = var/cov\n",
    "        results.append(res)\n",
    "    stock[\"Beta\"] = results\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Risk Free Rate Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_risk_free_column(stock):\n",
    "    \"\"\"\n",
    "\n",
    "    Creates a new Rate column in the stock dataframe using riskfreerate file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    res : dataframe\n",
    "        updated dataframe with Rate column\n",
    "\n",
    "    \"\"\"\n",
    "    riskrates = pd.read_csv(os.path.join(os.getcwd(),\"Data//RiskFreeRate.csv\"))\n",
    "    riskrates[\"Date\"] = pd.to_datetime(riskrates[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    riskrates[\"Rate\"] = pd.to_numeric(riskrates[\"Rate\"])\n",
    "    res = pd.merge(stock, riskrates, on=\"Date\", how = \"left\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Alpha Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alpha(stock):\n",
    "    \"\"\"\n",
    "\n",
    "    Creates a new Alpha column in the stock dataframe\n",
    "\n",
    "    alpha = %YTDCompany - (riskfreerate + (Beta * (%YTDSP500 - riskfreerate)))\n",
    "\n",
    "    %YTDCompany = percentage of year to date of the company\n",
    "\n",
    "    %YTDSP500 = percentage of year to date of the index file.(%YTD)\n",
    "\n",
    "    Beta = beta value from calculate_beta method.\n",
    "\n",
    "    %YTDCompany = ((Close Price of last available day / Close Price of today) - 1) * 100\n",
    "\n",
    "    riskfreerate : \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with new Alpha column\n",
    "    \"\"\"\n",
    "    outputpath = os.getcwd()\n",
    "    \n",
    "    stock[\"% YTD of Company\"] = ((stock.tail(1)['Close Price'].values[0]/stock[\"Close Price\"])-1)*100\n",
    "    ind = pd.read_csv(os.path.join(outputpath,\"Data\\\\modIndex.csv\"))\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    s = stock.Date.head(1).values[0]\n",
    "    e = stock.Date.tail(1).values[0]\n",
    "    ind = ind[ind.Date.between(e,s)]\n",
    "    ind.drop(['Open', 'High', 'Low', \"Close\", \"% Return\"], axis = 1,inplace=True) \n",
    "    ind.rename(columns={'% YTD':'% YTD of SP500'}, inplace=True)\n",
    "    ind[\"Date\"] = pd.to_datetime(ind[\"Date\"])\n",
    "    stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    stock = pd.merge(stock, ind, on=\"Date\", how = \"left\")\n",
    "    stock[\"Beta\"] = pd.to_numeric(stock[\"Beta\"],errors='coerce')\n",
    "    stock[\"Alpha\"] = stock[\"% YTD of Company\"]-(stock[\"Rate\"]+(stock[\"Beta\"]*(stock[\"% YTD of SP500\"] - stock[\"Rate\"])))\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lower Band, Upper Band, Band Area Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lower_band(stock):\n",
    "\n",
    "    \"\"\"\n",
    "    Creates new lower band column in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with lower band column\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # sorted_data = pd.DataFrame()\n",
    "    # sorted_data[\"Date\"] = stock[\"Date\"]\n",
    "    # sorted_data[\"Close Price\"] = stock[\"Close Price\"]\n",
    "    # sorted_data[\"Date\"] = pd.to_datetime(sorted_data[\"Date\"])\n",
    "    # stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    # sorted_data = sorted_data.sort_values(['Close Price', 'Date'], ascending=[True, False])\n",
    "    # start_date = stock.tail(1)[\"Date\"].values[0]\n",
    "\n",
    "    stock[\"Lower Band\"]=\"\"\n",
    "    for i,row in stock.iterrows():\n",
    "        # end_date = row[\"Date\"]\n",
    "        # close_price = row[\"Close Price\"]\n",
    "        stock.loc[i,\"Lower Band\"] = min(stock.loc[i:][\"Close Price\"])\n",
    "        # specific_dates = stock[stock.Date.between(start_date,end_date)]\n",
    "        # for index,j in specific_dates.iterrows():\n",
    "        #     stock.iloc[index,\"Lower Band\"] = close_price\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upper_band(stock):\n",
    "    \"\"\"\n",
    "    Creates new upper band column in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with upper band column\n",
    "    \n",
    "    \"\"\"\n",
    "    # sorted_data = pd.DataFrame()\n",
    "    # sorted_data[\"Date\"] = stock[\"Date\"]\n",
    "    # sorted_data[\"Close Price\"] = stock[\"Close Price\"]\n",
    "    # sorted_data[\"Date\"] = pd.to_datetime(sorted_data[\"Date\"])\n",
    "    # stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "    # sorted_data = sorted_data.sort_values(['Close Price', 'Date'], ascending=[False, True])\n",
    "    # end_date = stock.tail(1)[\"Date\"].values[0]\n",
    "    stock[\"Upper Band\"]=\"\"\n",
    "    for i,row in stock.iterrows():\n",
    "        # start_date = row[\"Date\"]\n",
    "        # close_price = row[\"Close Price\"]\n",
    "        stock.loc[i,\"Upper Band\"] = max(stock.loc[i:][\"Close Price\"])\n",
    "        # specific_dates = stock[stock.Date.between(start_date,end_date)]\n",
    "        # for index,j in specific_dates.iterrows():\n",
    "            # stock.loc[index,\"Upper Band\"] = close_price\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_band_area(stock):\n",
    "    \"\"\"\n",
    "    Creates new band area column in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with band area column\n",
    "    \n",
    "    \"\"\"\n",
    "    stock[\"Upper Band\"] = pd.to_numeric(stock[\"Upper Band\"])\n",
    "    stock[\"Lower Band\"] = pd.to_numeric(stock[\"Lower Band\"])\n",
    "    stock[\"Band Area\"] = stock[\"Upper Band\"]-stock[\"Lower Band\"]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lower_upper_bands(stock):\n",
    "    \"\"\"\n",
    "\n",
    "    Creates lower band, upper band, band area columns in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with lower, upper, band area columns\n",
    "\n",
    "    \"\"\"\n",
    "    stock[\"Lower Band\"]=\"\"\n",
    "    stock[\"Upper Band\"]=\"\"\n",
    "    stock[\"Band Area\"] = \"\"\n",
    "\n",
    "    for i,row in stock.iterrows():\n",
    "        maxv = max(stock.loc[i:][\"Close Price\"])\n",
    "        minv = min(stock.loc[i:][\"Close Price\"])\n",
    "        stock.loc[i,\"Upper Band\"] = maxv\n",
    "        stock.loc[i,\"Lower Band\"] = minv\n",
    "        stock.loc[i,\"Band Area\"] = maxv - minv\n",
    "    return stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create eps, pe_ratio, revenue, income, expenditure, profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eps_pe_ratio_revenue_income_expenditure_net_profit(rev,stk):\n",
    "    \"\"\"\n",
    "    Creates eps, pe, revenue, income, expenditure, profit columns.\n",
    "\n",
    "    Creates 2,4,8 bands for eps, pe, revenue, income, expenditure, profit columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    rev : dataframe\n",
    "        revenue dataframe\n",
    "    \n",
    "    stk : dataframe\n",
    "        stock dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stk : dataframe\n",
    "        updated dataframe after creating the columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    stk[\"Date\"] = pd.to_datetime(stk[\"Date\"])\n",
    "    s = min(rev.year)\n",
    "    e = max(rev.year)\n",
    "    cols = ['Revenue','Income','Expenditure','Net Profit','EPS']\n",
    "    stk[cols] = pd.DataFrame([[0]*len(cols)], index=stk.index)\n",
    "\n",
    "    rep = ['revenue','income','expenditure','profit','eps']\n",
    "\n",
    "    for index,row in stk.iterrows():\n",
    "        q = (row.Date.month-1)//3 + 1\n",
    "        samp = rev[(rev['year']==row.Date.year)&(rev['quartile']==q)]\n",
    "        if samp.shape[0] !=0:\n",
    "            stk.loc[index,cols] = samp.iloc[0][rep].values\n",
    "        else:\n",
    "            stk.loc[index,cols] = [np.nan]*5\n",
    "        \n",
    "    stk['year'] = pd.DatetimeIndex(stk['Date']).year\n",
    "    # stk = stk[(stk.year >= s)&(stk.year <= e) & stk[\"Revenue\"] !=0 ]\n",
    "    # stk = stk.drop([\"year\"],axis=1)\n",
    "\n",
    "    bands = [2,4,8]\n",
    "\n",
    "    for band in bands:\n",
    "        bcols = ['Revenue last '+str(band)+' quarters','Income last '+str(band)+' quarters','Expenditure  last '+str(band)+' quarters','Net Profit  last '+str(band)+' quarters','EPS last '+str(band)+' quarters']\n",
    "        stk[bcols] = pd.DataFrame([[0]*len(bcols)], index=stk.index)\n",
    "\n",
    "        for index,row in stk.iterrows():\n",
    "            q = (row.Date.month-1)//3 + 1\n",
    "            samp = rev[(rev['year']==row.Date.year)&(rev['quartile']==q)]\n",
    "            if samp.shape[0] == 0:\n",
    "                r = 1\n",
    "            else:\n",
    "                r = samp.index.values[0]\n",
    "            if r+band+1 < rev.shape[0]:\n",
    "                v = range(r+1,r+band+1)\n",
    "                stk.loc[index,bcols] = rev.loc[v,rep].sum().values\n",
    "    stk[\"p/e\"] = stk[\"Close Price\"]/stk[\"EPS\"]\n",
    "    return stk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create Next Day Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_next_day_columns(stock):\n",
    "    \"\"\"\n",
    "    Creates new Next Day columns in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with Next Day columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_columns = [\"Next Day Open Price\",\"Next Day High Price\",\"Next Day Low Price\",\"Next Day Close Price\"]\n",
    "    columns = [\"Open Price\",\"High Price\",\"Low Price\",\"Close Price\"]\n",
    "    stock[new_columns] = pd.DataFrame([[0,0,0,0]], index=stock.index)\n",
    "    stock[new_columns] = stock[columns].shift(1)\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growth Rate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_columns = ['Open Price', 'High Price', 'Low Price', 'Close Price','Next Day Open Price', 'Next Day High Price', 'Next Day Low Price', 'Next Day Close Price','WAP','No.of Shares', 'No. of Trades', 'Total Turnover (Rs.)','Deliverable Quantity', '% Deli. Qty to Traded Qty','Spread High-Low','Spread Close-Open','Alpha','Beta']\n",
    "growth_direct_rate_columns = [col + \" GR\" for col in direct_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Growth Rate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gain_loss(stock):\n",
    "    \"\"\"\n",
    "    Creates new growth rate columns in the stock dataframe.\n",
    "\n",
    "    Growth rate = (X-Y)/Y\n",
    "    \n",
    "    X = value of today\n",
    "    Y = value of the previous trading day\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created columns.\n",
    "\n",
    "    \"\"\"\n",
    "    direct_columns = ['Open Price', 'High Price', 'Low Price', 'Close Price','Next Day Open Price', 'Next Day High Price', 'Next Day Low Price', 'Next Day Close Price','WAP','No.of Shares', 'No. of Trades', 'Total Turnover (Rs.)','Deliverable Quantity', '% Deli. Qty to Traded Qty','Spread High-Low','Spread Close-Open','Alpha','Beta']\n",
    "    growth_direct_rate_columns = [col + \" GR\" for col in direct_columns]\n",
    "    stock[direct_columns] = stock[direct_columns].apply(pd.to_numeric,errors=\"coerce\")\n",
    "    stock[growth_direct_rate_columns] = pd.DataFrame([[0]*len(growth_direct_rate_columns)], index=stock.index)\n",
    "    today = stock[direct_columns]\n",
    "    previous = stock[direct_columns].shift(1)\n",
    "    stock[growth_direct_rate_columns] = (today-previous)/previous\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase(stock):\n",
    "    \"\"\"\n",
    "    Creates new Sequential Increase column in the stock dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created column.\n",
    "    \"\"\"\n",
    "    \n",
    "    stock[\"Sequential Increase\"] = \"\"\n",
    "    c = 0\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Increase\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Increase\"] = 0\n",
    "    for i in range(stock.shape[0]-2, 0, -1):\n",
    "        if stock.at[i,\"Close Price\"] > stock.at[i+1,\"Close Price\"]:\n",
    "            c += 1\n",
    "            stock.at[i-1,\"Sequential Increase\"] = c\n",
    "        else:\n",
    "            stock.at[i-1,\"Sequential Increase\"] = 0\n",
    "            c = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_decrease(stock):\n",
    "    \"\"\"\n",
    "    Creates new Sequential Decrease column in the stock dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created column.\n",
    "    \"\"\"\n",
    "\n",
    "    stock[\"Sequential Decrease\"] = 0\n",
    "    c = 1\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Decrease\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Decrease\"] = 0\n",
    "    for i in range(stock.shape[0]-2, 0, -1):\n",
    "        if stock.at[i,\"Close Price\"] < stock.at[i+1,\"Close Price\"]:\n",
    "            stock.at[i-1,\"Sequential Decrease\"] = c\n",
    "            c += 1\n",
    "        else:\n",
    "            stock.at[i-1,\"Sequential Decrease\"] = 0\n",
    "            c = 1\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Increase Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase_percentage(stock):\n",
    "    \"\"\"\n",
    "    Creates new Sequential Increase % column in the stock dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created column.\n",
    "    \"\"\"\n",
    "    \n",
    "    stock[\"Sequential Increase %\"] = \"\"\n",
    "    for i in range(stock.shape[0]-2):\n",
    "        if stock.at[i, \"Sequential Increase\"] != 0:\n",
    "            inc = stock.at[i, \"Sequential Increase\"]\n",
    "        else:\n",
    "            inc = 1\n",
    "        fr = stock.at[i+1, \"Close Price\"]\n",
    "        to = stock.at[i+1+inc, \"Close Price\"]\n",
    "        stock.at[i, \"Sequential Increase %\"] = (fr - to) / to\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Increase %\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Increase %\"] = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Decrease Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_decrease_percentage(stock):\n",
    "    \"\"\"\n",
    "    Creates new Sequential Decrease % column in the stock dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created column.\n",
    "    \"\"\"\n",
    "    \n",
    "    stock[\"Sequential Decrease %\"] = \"\"\n",
    "    for i in range(stock.shape[0]-2):\n",
    "        if stock.at[i, \"Sequential Decrease\"] != 0:\n",
    "            inc = stock.at[i, \"Sequential Decrease\"]\n",
    "        else:\n",
    "            inc = 1\n",
    "        fr = stock.at[i+1, \"Close Price\"]\n",
    "        to = stock.at[i+1+inc, \"Close Price\"]\n",
    "        stock.at[i, \"Sequential Decrease %\"] = (to - fr) / fr\n",
    "    stock.at[stock.shape[0]-2, \"Sequential Decrease %\"] = 0\n",
    "    stock.at[stock.shape[0]-1, \"Sequential Decrease %\"] = 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential max min avg increase, max min avg decrease for 90, 180, 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_avg_of_sequential_data(stock):\n",
    "    \"\"\"\n",
    "    Creates lists for increasing and decreasing % for Sequential Increase and Sequential Decrease columns dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    seq_inc_list : list\n",
    "\n",
    "    seq_dec_list : list\n",
    "\n",
    "    \"\"\"\n",
    "    index_start = stock.first_valid_index() \n",
    "    seq_inc_days = stock.at[index_start, \"Sequential Increase\"]\n",
    "    seq_dec_days = stock.at[index_start, \"Sequential Decrease\"]\n",
    "    seq_inc_list = [0]\n",
    "    seq_dec_list = [0]\n",
    "    for i in range(index_start, stock.shape[0]+index_start):\n",
    "        if stock.at[i, \"Sequential Increase\"] == seq_inc_days:\n",
    "            seq_inc_list.append(stock.at[i, \"Sequential Increase %\"])\n",
    "        if stock.at[i, \"Sequential Decrease\"] == seq_dec_days:\n",
    "            seq_dec_list.append(stock.at[i, \"Sequential Decrease %\"])\n",
    "    seq_inc_list = [i for i in seq_inc_list if i != 0 and i]\n",
    "    seq_dec_list = [i for i in seq_dec_list if i != 0 and i]\n",
    "    return seq_inc_list, seq_dec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_increase_decrease(stock):\n",
    "    \"\"\"\n",
    "    Creates new max, min, avg columns for Sequential Increase and Sequential Decrease columns \n",
    "    with 90, 180, 365 bands in stock dataframe.\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stock : dataframe\n",
    "\n",
    "        updated dataframe with newly created column.\n",
    "\n",
    "    \"\"\"\n",
    "    bands = [90,180,365]\n",
    "    for b in bands:\n",
    "        bcols = [\"Max Inc % in \"+str(b)+\" days\",\"Max Dec % in \"+str(b)+\" days\",\"Min Inc % in \"+str(b)+\" days\",\"Min Dec % in \"+str(b)+\" days\",\"Avg Inc % in \"+str(b)+\" days\",\"Avg Dec % in \"+str(b)+\" days\"]\n",
    "        stock[bcols] = pd.DataFrame([[0]*len(bcols)], index=stock.index)\n",
    "        for i in range(stock.shape[0]):\n",
    "            s = i+1\n",
    "            specific_bands = stock.iloc[-(s):-(s+b+1):-1]\n",
    "            specific_bands.sort_index(inplace=True)\n",
    "            seq_inc_list, seq_dec_list = max_min_avg_of_sequential_data(specific_bands)\n",
    "            try:\n",
    "                stock.loc[specific_bands.index,bcols] = [max(seq_inc_list),max(seq_dec_list),min(seq_inc_list),min(seq_dec_list),np.mean(seq_inc_list),np.mean(seq_dec_list)]\n",
    "            except:\n",
    "                continue\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuaterWise growth rate for \"Revenue\",\"Dividend\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Revenue\",\"Dividend Value\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary_for_quarterwise_data(stock,columnName):\n",
    "    \"\"\"\n",
    "\n",
    "    generates a dictionary for the given column quaterwise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    columnName : string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    result : dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    stock.Date = pd.to_datetime(stock.Date)\n",
    "    for index,row in stock.iterrows():\n",
    "        try:\n",
    "            q = (row.Date.month-1)//3 + 1   \n",
    "            year = row.Date.year\n",
    "            month = row.Date.month\n",
    "            res = result.get(year,{})\n",
    "            # amount = re.findall(r\"\\d+.?\\d*\",row[\"Revenue\"])[0]\n",
    "            amount  = row[columnName]\n",
    "            q = \"1q\" if 1 <= month <= 3 else \"2q\" if 4 <= month <= 6 else \"3q\" if 6 <= month <= 9 else \"4q\"\n",
    "            val = res.get(q,[])\n",
    "            val.append(float(amount))\n",
    "            res[q] = val\n",
    "            result[year] = res\n",
    "        except:\n",
    "            continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dictionary_for_quarterwise_growthrate_data(data):\n",
    "    \"\"\"\n",
    "\n",
    "    generates a dictionary for quater wise growth rate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    data : dictionary\n",
    "\n",
    "    columnName : string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    gr_dic : dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    gr_dic = {}\n",
    "    keys = list(data.keys())\n",
    "    array = [''] * (len(keys)*4)\n",
    "    array_index = 0\n",
    "    for key in data:\n",
    "        lists = data.get(key)\n",
    "        array_index += 4 - len(lists.keys()) \n",
    "        for lis in lists:\n",
    "            if math.isnan(lists.get(lis)[0]):\n",
    "                array[array_index] = ''\n",
    "            else:                \n",
    "                array[array_index] = lists.get(lis)[0]\n",
    "            array_index = array_index + 1\n",
    "    if (array.count('')) > ((len(keys) * 4) / 2):\n",
    "        return gr_dic\n",
    "    \n",
    "    for i in range(4,len(keys)*4,4):\n",
    "        res = [array[i],array[i+1],array[i+2],array[i+3]]\n",
    "        avg = np.mean(list(filter(lambda i: isinstance(i, float), res)))\n",
    "        if np.isnan(avg):\n",
    "            pass\n",
    "        else:\n",
    "            array[i] = avg\n",
    "\n",
    "    gr_array = [''] * (len(keys)*4)\n",
    "    for i in range(0, len(keys)*4-1):\n",
    "        x = array[i]\n",
    "        y = array[i+1]\n",
    "        if x == '' and y == '': continue\n",
    "        if y == '' or y == 0: continue\n",
    "        if x == '':\n",
    "            gr_array[i] = 1\n",
    "        else:\n",
    "            gr_array[i] = (x - y) / y\n",
    "    index = 0\n",
    "    for key in data:\n",
    "        gr_dic[key] = [gr_array[index], gr_array[index+1], gr_array[index+2], gr_array[index+3]]\n",
    "        index = index + 4\n",
    "    return gr_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_growthrate_for_quarterwise_data(gr_dic, stock, columnName):\n",
    "    \"\"\"\n",
    "\n",
    "    generates a dictionary for the given column quaterwise.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gr_dic : dictionary\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    columnName : string\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    for i in range(0, stock.shape[0]-1):\n",
    "        date = stock.at[i, \"Date\"]\n",
    "        q = int((date.month-1)//3)\n",
    "        year = date.year\n",
    "        if year in gr_dic.keys():\n",
    "            stock.at[i,columnName+\" GR\"] = gr_dic.get(year)[q] if isinstance(gr_dic.get(year)[q],float) else 0\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quarter_wise_growthrate(stock, columnName):\n",
    "    \"\"\"\n",
    "\n",
    "    Creates new Growth Rate column in the stock dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    columnName : string\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "\n",
    "    stock : dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    dic = generate_dictionary_for_quarterwise_data(stock, columnName)\n",
    "    gr_dic = generate_dictionary_for_quarterwise_growthrate_data(dic)\n",
    "    stock[columnName + ' GR'] = ''\n",
    "    if gr_dic == {}:\n",
    "        return stock\n",
    "    else:\n",
    "        stock = update_growthrate_for_quarterwise_data(gr_dic, stock, columnName)\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Price as percentage of Lowest Value, Highest Value, Band Area for 7, 30, 90, 180, 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_price_as_percent_of_LV_HV_BA(stock):\n",
    "    \"\"\"\n",
    "    Creates new growth rate columns in the stock dataframe.\n",
    "    For Close Price as% Lowest Value, close price as% Highest Value, close price as% Band Area\n",
    "    for 7, 30, 90, 180, 365 bands\n",
    "\n",
    "    Close Price as % of Lowest Value = Close Price of that day/min close price in the band\n",
    "    Close Price as % of Highest Value = Close Price of that day/max close price in the band\n",
    "    Close Price as % of Band Area = Close Price of that day / (max-min close price in the band)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    stock : dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    stock : dataframe\n",
    "        updated dataframe with newly created columns.\n",
    "    \"\"\"\n",
    "\n",
    "    bands = [7,30,90,180,365]\n",
    "    for b in bands:\n",
    "        bcols = [\"CP % LV \"+str(b)+\" days\",\"CP % HV \"+str(b)+\" days\",\"CP % BA \"+str(b)+\" days\"]\n",
    "        stock[bcols] = pd.DataFrame([[0]*len(bcols)], index=stock.index)\n",
    "        for i in range(stock.shape[0]):\n",
    "            s = i+1\n",
    "            specific_bands = stock.iloc[-(s):-(s+b+1):-1]\n",
    "            low = specific_bands[\"Close Price\"].min()\n",
    "            high = specific_bands[\"Close Price\"].max()\n",
    "            today = stock.iloc[-(s)][\"Close Price\"]\n",
    "            stock.loc[specific_bands.index,bcols] = [today/low,today/high,today/(high-low)]\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For full Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputpath = os.getcwd()\n",
    "# outputpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputpath = \"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\\"\n",
    "outputpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(outputpath+\"/\"+\"Stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = pd.read_csv(\"../input/newdata/my.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity = pd.read_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Equity.csv\")\n",
    "security_numbers = df_equity[\"Security Code\"].tolist()\n",
    "security_names = df_equity[\"Security Name\"].tolist()\n",
    "companies = {str(k) : v for (k, v) in list(zip(security_numbers, security_names))}\n",
    "companies[\"542602\"] = \"Embassy Office Parks REIT\"\n",
    "companies[\"500112\"] = \"State Bank of India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 500002.csv ABB India Limited\n",
      "2 500003.csv AEGIS LOGISTICS LTD.\n",
      "2015-09-15 00:00:00 2007-08-01T00:00:00.000000000\n",
      "3 500008.csv AMARA RAJA BATTERIES LTD.\n",
      "2012-09-24 00:00:00 2007-08-01T00:00:00.000000000\n",
      "4 500009.csv AMBALAL SARABHAI ENTERPRISES LTD.\n",
      "5 500010.csv HOUSING DEVELOPMENT FINANCE CORP.LTD.\n",
      "2010-08-17 00:00:00 2007-08-01T00:00:00.000000000\n",
      "6 500012.csv ANDHRA PETROCHEMICALS LTD.\n",
      "7 500013.csv ANSAL PROPERTIES & INFRASTRUCTURE LTD.\n",
      "8 500014.csv Utique Enterprises Ltd\n",
      "9 500016.csv ARUNA HOTELS LTD.\n",
      "10 500020.csv BOMBAY DYEING & MFG.CO.LTD.\n",
      "2012-10-29 00:00:00 2007-08-01T00:00:00.000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<timed exec>\", line 11, in <module>\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 462, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 819, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1050, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1867, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1362, in _open_handles\n",
      "    self.handles = get_handle(\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\common.py\", line 642, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Corporate Actions1\\\\Corporate_Actions_500014.csv'\n",
      "Traceback (most recent call last):\n",
      "  File \"<timed exec>\", line 11, in <module>\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 462, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 819, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1050, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1867, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1362, in _open_handles\n",
      "    self.handles = get_handle(\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\common.py\", line 642, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Corporate Actions1\\\\Corporate_Actions_500016.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 500023.csv Asian Hotels (North) Limited\n",
      "12 500027.csv ATUL LTD.\n",
      "13 500028.csv ATV PROJECTS INDIA LTD.\n",
      "14 500031.csv BAJAJ ELECTRICALS LTD.-$\n",
      "2010-01-27 00:00:00 2007-08-01T00:00:00.000000000\n",
      "15 500032.csv Bajaj Hindusthan Sugar Limited\n",
      "16 500033.csv FORCE MOTORS LTD.-$\n",
      "17 500034.csv Bajaj Finance Limited\n",
      "2016-09-07 00:00:00 2009-05-18T00:00:00.000000000\n",
      "18 500038.csv BALRAMPUR CHINI MILLS LTD.\n",
      "19 500039.csv BANCO PRODUCTS (INDIA) LTD.-$\n",
      "20 500040.csv CENTURY TEXTILES & INDUSTRIES LTD.\n",
      "21 500041.csv BANNARI AMMAN SUGARS LTD.\n",
      "22 500042.csv BASF INDIA LTD.\n",
      "23 500043.csv BATA INDIA LTD.\n",
      "2015-10-06 00:00:00 2007-08-01T00:00:00.000000000\n",
      "24 500048.csv BEML LTD.\n",
      "25 500049.csv BHARAT ELECTRONICS LTD.\n",
      "2017-03-15 00:00:00 2007-08-01T00:00:00.000000000\n",
      "26 500052.csv BHANSALI ENGINEERING POLYMERS LTD.-$\n",
      "27 500055.csv Tata Steel Bsl Ltd\n",
      "2010-09-20 00:00:00 2007-08-01T00:00:00.000000000\n",
      "28 500058.csv BIHAR SPONGE IRON LTD.\n",
      "29 500060.csv Birla Cable Ltd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<timed exec>\", line 11, in <module>\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 462, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 819, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1050, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1867, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1362, in _open_handles\n",
      "    self.handles = get_handle(\n",
      "  File \"C:\\Users\\venu\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\common.py\", line 642, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Corporate Actions1\\\\Corporate_Actions_500058.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 500067.csv BLUE STAR LTD.\n",
      "Wall time: 1h 36min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cols = [\"Revenue\",\"Dividend Value\",\"Income\",\"Expenditure\",\"Net Profit\",\"EPS\"]\n",
    "count = 0\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock1\")):\n",
    "    if (filename.startswith(\"5\")):\n",
    "        count += 1\n",
    "        security_code = os.path.join(path, \"Data\\\\Stock1\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = security_code[0 : 6]\n",
    "        try:\n",
    "            print(count, security_code, companies[stock])\n",
    "            index_df = pd.read_csv(os.path.join(path,\"Data\\\\Index.csv\"))\n",
    "            corporate_df = pd.read_csv(os.path.join(path,\"Data\\\\Corporate Actions1\\\\Corporate_Actions_\"+stock+\".csv\"))\n",
    "            revenue_df = pd.read_csv(os.path.join(path,\"Data\\\\Revenue1\\\\\"+stock+\".csv\"))\n",
    "            stock_df = pd.read_csv(os.path.join(path,\"Data\\\\Stock1\\\\\"+stock+\".csv\"))\n",
    "\n",
    "            stock_df = cleaning(stock_df,index_df)\n",
    "            stock_df = apply_corporate_actions(stock_df,corporate_df)\n",
    "            create_index(outputpath)\n",
    "            stock_df = calculate_beta(stock_df)\n",
    "            stock_df = add_risk_free_column(stock_df)\n",
    "            stock_df = calculate_alpha(stock_df)\n",
    "            stock_df = create_lower_upper_bands(stock_df)\n",
    "            stock_df = create_eps_pe_ratio_revenue_income_expenditure_net_profit(revenue_df,stock_df)\n",
    "            stock_df = add_next_day_columns(stock_df)\n",
    "\n",
    "            stock_df.to_csv(os.path.join(outputpath,\"Stock1\\\\\"+\"fc\"+str(security_code)),index=None)\n",
    "            stock_df = pd.read_csv(os.path.join(outputpath,\"Stock1\\\\\"+\"fc\"+str(security_code)))\n",
    "\n",
    "            stock_df[direct_columns] = stock_df[direct_columns].apply(pd.to_numeric,errors=\"coerce\")\n",
    "            stock_df = find_gain_loss(stock_df)\n",
    "            stock_df = sequential_increase(stock_df)\n",
    "            stock_df = sequential_decrease(stock_df)\n",
    "            stock_df = sequential_increase_percentage(stock_df)\n",
    "            stock_df = sequential_decrease_percentage(stock_df)\n",
    "            stock_df = sequential_increase_decrease(stock_df)\n",
    "\n",
    "            for col in cols:\n",
    "                try:\n",
    "                    stock_df = quarter_wise_growthrate(stock_df, col)\n",
    "                except Exception as e:\n",
    "                    traceback.print_exc()\n",
    "            stock_df = close_price_as_percent_of_LV_HV_BA(stock_df)\n",
    "            stock_df.to_csv(os.path.join(outputpath,\"Stock1\\\\\"+\"gr\"+str(security_code)),index=None)\n",
    "\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        \n",
    "        if (count == 30):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
