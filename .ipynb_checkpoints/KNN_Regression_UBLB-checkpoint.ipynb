{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pending-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import prettytable\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "auburn-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-holly",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "    \n",
    "    data.drop(columns=['Unixtime','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if null_threshold * total / 100 < data[col].isnull().sum():\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.apply(pd.to_numeric,errors='coerce')\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-youth",
   "metadata": {},
   "source": [
    "# Necessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lyric-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_with_necessary_columns(data):\n",
    "    necessary_columns = ['Dividend Value', '% Return of Company', '% Return of SP500', 'Next Day Open Price', 'Next Day High Price',\n",
    "                     'Next Day Low Price', 'Next Day Close Price', 'Open Price GR', 'High Price GR', 'Low Price GR', 'Close Price GR',\n",
    "                     'Next Day Open Price GR', 'Next Day High Price GR', 'Next Day Low Price GR', 'Next Day Close Price GR',\n",
    "                     'WAP GR', 'No.of Shares GR', 'No. of Trades GR', 'Total Turnover (Rs.) GR', 'Deliverable Quantity GR',\n",
    "                     '% Deli. Qty to Traded Qty GR', 'Spread High-Low GR', 'Spread Close-Open GR', 'Alpha GR', 'Beta GR',\n",
    "                     'Sequential Increase %', 'Sequential Decrease %', 'Max Inc % in 90 days', 'Max Dec % in 90 days',\n",
    "                     'Min Inc % in 90 days', 'Min Dec % in 90 days', 'Avg Inc % in 90 days', 'Avg Dec % in 90 days',\n",
    "                     'Max Inc % in 180 days', 'Max Dec % in 180 days', 'Min Inc % in 180 days', 'Min Dec % in 180 days',\n",
    "                     'Avg Inc % in 180 days', 'Avg Dec % in 180 days', 'Max Inc % in 365 days', 'Max Dec % in 365 days',\n",
    "                     'Min Inc % in 365 days', 'Min Dec % in 365 days', 'Avg Inc % in 365 days', 'Avg Dec % in 365 days',\n",
    "                     'Revenue GR', 'Dividend Value GR', 'Income GR', 'Expenditure GR', 'Net Profit GR', 'EPS GR',\n",
    "                     'CP % LV 7 days', 'CP % HV 7 days', 'CP % BA 7 days', 'CP % LV 30 days', 'CP % HV 30 days', 'CP % BA 30 days',\n",
    "                     'CP % LV 90 days', 'CP % HV 90 days', 'CP % BA 90 days', 'CP % LV 180 days', 'CP % HV 180 days',\n",
    "                     'CP % BA 180 days', 'CP % LV 365 days', 'CP % HV 365 days', 'CP % BA 365 days', 'LowerBandInLast1Months',\n",
    "                     'UpperBandInLast1Months', 'LowerBandInNext1Months', 'UpperBandInNext1Months', 'LowerBandInLast3Months',\n",
    "                     'UpperBandInLast3Months', 'LowerBandInNext3Months', 'UpperBandInNext3Months', 'LowerBandInLast6Months',\n",
    "                     'UpperBandInLast6Months', 'LowerBandInNext6Months', 'UpperBandInNext6Months', 'LowerBandInLast9Months',\n",
    "                     'UpperBandInLast9Months', 'LowerBandInNext9Months', 'UpperBandInNext9Months', 'LowerBandInLast12Months',\n",
    "                     'UpperBandInLast12Months', 'LowerBandInNext12Months', 'UpperBandInNext12Months', 'LowerBandInLast24Months',\n",
    "                     'UpperBandInLast24Months', 'LowerBandInNext24Months', 'UpperBandInNext24Months']\n",
    "    \n",
    "    n_cols = []\n",
    "    d_cols = list(data.columns)\n",
    "    for col in necessary_columns:\n",
    "        if (col in d_cols):\n",
    "            n_cols.append(col)\n",
    "            \n",
    "    data = data[n_cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "superior-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_startswithnext_UBLB(data):\n",
    "    cols = [col for col in data.columns if (not (col.lower().startswith(\"next\")))]\n",
    "    data = data[cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "micro-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ycolumn_columns(data, column):\n",
    "    cols = [col for col in data.columns]\n",
    "    cols.remove(column)\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-hollywood",
   "metadata": {},
   "source": [
    "# Removing columns based on the dependent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complimentary-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    \"\"\"\n",
    "    Removes all the Next Day columns.\n",
    "    Removes all the non Growth Rate Columns (GR)\n",
    "    add the predictor column to list of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    column : string\n",
    "        name of the predictor column \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    column : string\n",
    "        name of the predictor column\n",
    "    \"\"\"\n",
    "    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-gallery",
   "metadata": {},
   "source": [
    "# For predicting UB, LB percentage columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equal-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_next_columns_UBLB(data):\n",
    "    cols = [col for col in data.columns if (\"next\" not in col.lower())]\n",
    "    data = data[cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hourly-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_CP_columns_UBLB(data):\n",
    "    cols = [col for col in data.columns if (\"cp\" not in col.lower())]\n",
    "    data = data[cols]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interpreted-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_LowerBand_columns_UBLB(data, column):\n",
    "    cols = [col for col in data.columns if (\"lv\" not in col.lower() and \"low\" not in col.lower())]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trying-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_UpperBand_columns_UBLB(data, column):\n",
    "    cols = [col for col in data.columns if (\"hv\" not in col.lower() and \"upper\" not in col.lower())]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-oakland",
   "metadata": {},
   "source": [
    "# Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sonic-prairie",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[0;32m   3086\u001b[0m         \u001b[1;31m# Store raw and processed history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3087\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstore_history\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3088\u001b[1;33m             self.history_manager.store_inputs(self.execution_count,\n\u001b[0m\u001b[0;32m   3089\u001b[0m                                               cell, raw_cell)\n\u001b[0;32m   3090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\history.py\u001b[0m in \u001b[0;36mstore_inputs\u001b[1;34m(self, line_num, source, source_raw)\u001b[0m\n\u001b[0;32m    717\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_hist_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_input_cache_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_input_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[1;31m# Trigger to flush cache and write to DB.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def forward_selection_SFS(n_neighbors, n_features_to_select, X, y):\n",
    "    knn = KNeighborsRegressor(n_neighbors = n_neighbors)  \n",
    "    sfs = SequentialFeatureSelector(knn, n_features_to_select = n_features_to_select)\n",
    "    sfs.fit(X, y)\n",
    "    sup = sfs.get_support()\n",
    "    cols = list(X.columns)\n",
    "\n",
    "    ff = []\n",
    "    for i in range(len(sup)):\n",
    "        if (sup[i]):\n",
    "            ff.append(cols[i])\n",
    "            \n",
    "    return ff\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection_SFS(n_neighbors, n_features_to_select, X, y):\n",
    "    knn = KNeighborsRegressor(n_neighbors = n_neighbors)  \n",
    "    sfs = SequentialFeatureSelector(knn, n_features_to_select = n_features_to_select, direction = 'backward')\n",
    "    sfs.fit(X, y)\n",
    "    sup = sfs.get_support()\n",
    "    cols = list(X.columns)\n",
    "\n",
    "    bf = []\n",
    "    for i in range(len(sup)):\n",
    "        if (sup[i]):\n",
    "            bf.append(cols[i])\n",
    "\n",
    "    return bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_knn = pd.read_csv(os.path.join(path,\"Data\\Stock1\\\\\" + \"UBLBPASTNEXTgr500112.csv\"))\n",
    "# df1 = pre_process_data(df_knn, 60)\n",
    "# df1 = data_with_necessary_columns(df1)\n",
    "# df1 = remove_columns_startswithnext_UBLB(df1)\n",
    "# column = \"LowerBandInNext1Months\"\n",
    "# df1 = remove_ycolumn_columns(df1, column)\n",
    "# print(len(df1.columns))\n",
    "\n",
    "# X = df1[df1.columns[:-1]]\n",
    "# Y = df1[column]\n",
    "\n",
    "\n",
    "# fs = forward_selection_SFS(3, (df1.shape[1] // 3), X, Y)\n",
    "# print(fs, len(fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs = backward_selection_SFS(3, (df1.shape[1] // 3), X, Y)\n",
    "# print(bs, len(bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]]).astype(float)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features]).astype(float)\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-witch",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_parameters(X,Y):\n",
    "    params = {'n_neighbors':np.arange(1,105,5), 'weights':['uniform', 'distance'], 'metric':['euclidean', 'manhattan']}\n",
    "    knn = KNeighborsRegressor()\n",
    "    model = GridSearchCV(knn, params)\n",
    "    model.fit(X,Y)\n",
    "    k = model.best_params_['n_neighbors']\n",
    "    params = {'n_neighbors':np.arange(k-5, k+5), 'weights':['uniform', 'distance'], 'metric':['euclidean', 'manhattan']}\n",
    "    knn = KNeighborsRegressor()\n",
    "    model = GridSearchCV(knn, params)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(X,Y, method, value, name, column):\n",
    "    params = best_parameters(X,Y)\n",
    "    \n",
    "#     scaler = StandardScaler()\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_train = pd.DataFrame(X_train)\n",
    "    \n",
    "#     X_test = scaler.fit_transform(X_test)\n",
    "#     X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "#     y_train = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "#     y_train = pd.DataFrame(y_train)\n",
    "\n",
    "    X_test = X[ : int(X.shape[0] * 0.3)]\n",
    "    X_train = X[int(X.shape[0] * 0.3) : ]\n",
    "    y_test = Y[ : int(X.shape[0] * 0.3)]\n",
    "    y_train = Y[int(X.shape[0] * 0.3) :]\n",
    "\n",
    "    knn = KNeighborsRegressor(**params)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "#     y_pred = scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    \n",
    "    pred_actual = pd.DataFrame(list(zip(y_pred, y_test)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "    pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\NextUBLB_Results\\\\\" + name[14 : 20] + \"_KNN_Regression_\" + \"FI_\" + method + \"_\" + column + \"_\" + str(value) + \".csv\" , index = False)\n",
    "    \n",
    "    \n",
    "    myres =  {\"RMSE\":rmse,\"MAE\":mae,\"MSE\":mse}\n",
    "    myres.update(params)\n",
    "    myres.update({\"r2_score\" : r2})\n",
    "    \n",
    "    return myres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-pioneer",
   "metadata": {},
   "source": [
    "# Finding results from each set of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_KNN(df, column, method, value, name, results):\n",
    "    print(\"KNN Model fitted using columns obtained from feature importance using \" + method + \" : \")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column]\n",
    "    \n",
    "    \n",
    "    model_result = k_nearest_neighbours(X,Y, method, value, name, column)\n",
    "    \n",
    "    print(\"R2_Score ----> \", model_result[\"r2_score\"])\n",
    "    \n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)] = {}\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['r2_score'] = model_result['r2_score']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['RMSE'] = model_result['RMSE']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['MAE'] = model_result['MAE']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['MSE'] = model_result['MSE']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['n_neighbors'] = model_result['n_neighbors']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['weights'] = model_result['weights']\n",
    "    results[\"KNN_Regression_FI_\" + method + \"_\" + str(value)]['metric'] = model_result['metric']\n",
    "    \n",
    "    \n",
    "    \n",
    "    create_pretty_table(name , \"KNN_Regression\", method + \" \" + value, model_result, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_ForwardSelection(df1, name, column, results):\n",
    "    print(\"Features Importance using Forward Selection Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"ForwardSelection\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column]\n",
    "    forward_features = forward_selection_SFS(3, (df1.shape[1] // 3), X, Y)\n",
    "    print(\"Features obtained from Forward Selection method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(forward_features)\n",
    "    if (len(forward_features) != 0):\n",
    "        forward_features.append(column)\n",
    "        df_fs = df1[forward_features]\n",
    "        fit_KNN(df_fs, column, method, '', name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_BackwardElimination(df1, name, column, results):\n",
    "    print(\"Features Importance using Backward Elimination Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"BackwardElimination\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column]\n",
    "    backward_features = backward_selection_SFS(3, (df1.shape[1] // 3), X, Y)\n",
    "    print(\"Features obtained from Backward Elimination method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(backward_features)\n",
    "    if (len(backward_features) != 0):\n",
    "        backward_features.append(column)\n",
    "        df_be = df1[backward_features]\n",
    "        fit_KNN(df_be, column, method, '', name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_AllFeatures(df1, name, column, results):\n",
    "    print(\"All Features are considered : \")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"AllFeaturesConsideration\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column]\n",
    "    all_features = list(X.columns)\n",
    "    print(\"All Features are --->>\") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(all_features)\n",
    "    if (len(all_features) != 0):\n",
    "        all_features.append(column)\n",
    "        df_all = df1[all_features]\n",
    "        fit_KNN(df_all, column, method, '', name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_each_set(data, name, final_df, column):\n",
    "    df = pre_process_data(data, 60)\n",
    "    \n",
    "    df1 = data_with_necessary_columns(df)\n",
    "    df1 = remove_columns_startswithnext_UBLB(df1)\n",
    "    df1 = remove_ycolumn_columns(df1, column)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    get_results_from_FI_AllFeatures(df1, name, column, results)\n",
    "    get_results_from_FI_ForwardSelection(df1, name, column, results)\n",
    "#     get_results_from_FI_BackwardElimination(df1, name, column, results)\n",
    "    \n",
    "    \n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1]['r2_score'])\n",
    "    max_row = {'Company' : name[14 : 20] + \"-\" + companies[name[14 : 20]], 'Y-Column' : column, 'Model' : 'KNN-Regression', 'Method' : sorted_results[-1][0],\n",
    "               'RMSE' : sorted_results[-1][1]['RMSE'], 'MAE' : sorted_results[-1][1]['MAE'], 'MSE' : sorted_results[-1][1]['MSE'],\n",
    "              'n_neighbors' : sorted_results[-1][1]['n_neighbors'],'weights' : sorted_results[-1][1]['weights'],\n",
    "               'metric' : sorted_results[-1][1]['metric'], 'r2_score' : sorted_results[-1][1]['r2_score']}\n",
    "    final_df = final_df.append(max_row, ignore_index = True)\n",
    "    print(\"Maximum correct direction values are obtained for {} with r2_score of {}.\".format(sorted_results[-1][0], sorted_results[-1][1]['r2_score']))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-reconstruction",
   "metadata": {},
   "source": [
    "# Process of getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_table(name, model, method, result, column):\n",
    "    values = [name[14 : 20] + \"-\" + companies[name[14 : 20]], column, method] + [round(v, 6) if (not isinstance(v, str)) else v for k,v in result.items()]\n",
    "    tables[model].add_row(values)\n",
    "    tables[model].title = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Company','Y-Column','Method', 'RMSE','MAE','MSE','n_neighbors','weights','metric', 'r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity = pd.read_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Equity.csv\")\n",
    "security_numbers = df_equity[\"Security Code\"].tolist()\n",
    "security_names = df_equity[\"Security Name\"].tolist()\n",
    "companies = {str(k) : v for (k, v) in list(zip(security_numbers, security_names))}\n",
    "companies[\"542602\"] = \"Embassy Office Parks REIT\"\n",
    "companies[\"500112\"] = \"State Bank of India\"\n",
    "# companies[\"542602\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"KNN_Regression\"]\n",
    "tables = {model:PrettyTable() for model in models}\n",
    "for name,table in tables.items():\n",
    "    table.field_names = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['Company','Y-Column','Model','Method', 'RMSE','MAE','MSE','n_neighbors','weights','metric', 'r2_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\UBLB_Results\\\\Results_KNN.csv\")\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = final_columns)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "comp = [\"500023\", \"500027\", \"500028\", \"500112\"]\n",
    "\n",
    "\n",
    "# c = 0\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock1\")):\n",
    "#     if (c == 31):\n",
    "#         break\n",
    "    if filename.startswith(\"UBLBPASTNEXTgr\"):\n",
    "#         c += 1\n",
    "        name = os.path.join(path, \"Data\\Stock1\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = name[14 : 20]\n",
    "        print(stock)\n",
    "        if(stock not in comp):\n",
    "            print(\"continue\")\n",
    "            continue\n",
    "            \n",
    "        fd_df = pd.DataFrame(columns = final_df.columns)\n",
    "        y_columns = [\"LowerBandInNext1Months\", \"LowerBandInNext3Months\", \"LowerBandInNext6Months\",\n",
    "                    \"LowerBandInNext9Months\", \"LowerBandInNext12Months\", \"LowerBandInNext24Months\", \n",
    "                     \"UpperBandInNext1Months\", \"UpperBandInNext3Months\", \"UpperBandInNext6Months\",\n",
    "                     \"UpperBandInNext9Months\", \"UpperBandInNext12Months\", \"UpperBandInNext24Months\"]\n",
    "        for i in range(len(y_columns)):\n",
    "            col = y_columns[i]\n",
    "            df_knn = pd.read_csv(os.path.join(path,\"Data\\Stock1\\\\\" + filename))\n",
    "            \n",
    "            value = 0\n",
    "            if (\"24\" in col):\n",
    "                value = 24\n",
    "            elif (\"12\" in col):\n",
    "                value = 12\n",
    "            elif (\"9\" in col):\n",
    "                value = 9\n",
    "            elif (\"6\" in col):\n",
    "                value = 6\n",
    "            elif (\"3\" in col):\n",
    "                value = 3\n",
    "            else:\n",
    "                value = 1\n",
    "            \n",
    "            \n",
    "            df_knn[\"Date\"] = pd.to_datetime(df_knn[\"Date\"])\n",
    "            head_date = df_knn.loc[0, \"Date\"]\n",
    "            end_date = head_date - timedelta(days = value * 30)\n",
    "            tail = df_knn.shape[0] - 1\n",
    "            tail_date = df_knn.loc[tail, \"Date\"]\n",
    "            start_date = tail_date + timedelta(days = value * 30)\n",
    "            mask = (df_knn[\"Date\"] >= start_date) & (df_knn[\"Date\"] <= end_date)\n",
    "            df_kn = df_knn.loc[mask]\n",
    "            \n",
    "            print(\"For stock : \", stock, \"and Y-Column is :\", col)\n",
    "            print(\"#################################################################################################################\")\n",
    "            f_df = get_results_from_each_set(df_kn, name, fd_df, col)\n",
    "            final_df = final_df.append(f_df, ignore_index = True)\n",
    "            print(\"#################################################################################################################\")\n",
    "#             break\n",
    "        \n",
    "final_df = final_df.sort_values(by = ['Company', 'Y-Column','r2_score'], ascending = [True, True, False])\n",
    "final_df.to_csv('C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\NextUBLB_Results\\\\Results_KNN_30.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,table in tables.items():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = final_df.sort_values(by = ['Company', 'Y-Column','r2_score'], ascending = [True, True, False])\n",
    "# final_df.to_csv('C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\NextUBLB_Results\\\\Results_KNN_30.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-stress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
