{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from prettytable import PrettyTable\n",
    "import time \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import sys\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if ((null_threshold * total / 100) < data[col].isnull().sum()):\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing columns based on dependent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    cols = [col for col in data.columns if (\"next\" not in col.lower() and col.lower().endswith(\"gr\"))]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_Regression(X_train,Y_train):\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    ols_model = sm.OLS(Y_train, X_train).fit()\n",
    "#     print(list(zip(list(cols),ols_model.pvalues)))\n",
    "    rsquared_adj = ols_model.rsquared_adj\n",
    "    aic = ols_model.aic\n",
    "    bic = ols_model.bic\n",
    "    fvalue = ols_model.fvalue\n",
    "    return {\"rsquared_adj\":rsquared_adj,\"aic\":aic,\"bic\":bic,\"fvalue\":fvalue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(data, y):\n",
    "    # print(\"------ Linear Regression ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 0)\n",
    "    model = LinearRegression(fit_intercept = True)  \n",
    "    model.fit(X_train, Y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    confidence = model.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values, \"Confidence\" : confidence, \"Predicted\" : pred, \"Actual\" : Y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression with forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]]).astype(float)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_forward_selection(data,y):\n",
    "    # print(\"------ Linear Regression Forward Selection ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    forward_features = forward_selection(X,Y)\n",
    "    print(\"Features obtained from Forward Selection : \")\n",
    "    print(forward_features)\n",
    "    return linear_regression(data[forward_features+[y]],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression with backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features]).astype(float)\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_backward_selection(data,y):\n",
    "    # print(\"------ Linear Regression Backward Selection ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    backward_features = backward_elimination(X,Y)\n",
    "    print(\"Features obtained from Backward Elimination : \")\n",
    "    print(backward_features)\n",
    "    return linear_regression(data[backward_features+[y]],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inbuilt Forward Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection_inbuilt(X,Y,k,score):\n",
    "    sfs = SFS(LinearRegression(),k_features=k,forward=True,floating=False,scoring = score,cv = 0)\n",
    "    sfs.fit(X, Y)\n",
    "    lst = list(sfs.k_feature_names_)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_forward_selection_inbuit(data,y):\n",
    "    # print(\"------ Linear Regression Forward Selection Inbuilt ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    scores = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error',\n",
    "                  'neg_root_mean_squared_error','neg_median_absolute_error','r2']\n",
    "    df = pd.DataFrame(columns=scores,index=range(1,data.shape[1]+1))\n",
    "    for k in range(1,data.shape[1]+1):\n",
    "        for score in scores:\n",
    "            sfs = forward_selection_inbuilt(X,Y,k,score)\n",
    "            df.loc[k,score] = sfs\n",
    "    df.to_csv(\"forwardFeatures.csv\",index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inbuilt Backward Elimination Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection_inbuilt(X,Y,k,score):\n",
    "    sfs = SFS(LinearRegression(),k_features=k,forward=False,floating=False,scoring = score,cv = 0)\n",
    "    sfs.fit(X, Y)\n",
    "    lst = list(sfs.k_feature_names_)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_backward_selection_inbuit(data,y):\n",
    "    # print(\"------ Linear Regression Backward Selection Inbuilt ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    scores = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error',\n",
    "                  'neg_root_mean_squared_error','neg_median_absolute_error','r2']\n",
    "    df = pd.DataFrame(columns=scores,index=range(1,data.shape[1]+1))\n",
    "    for k in range(1,data.shape[1]+1):\n",
    "        for score in scores:\n",
    "            sfs = backward_selection_inbuilt(X,Y,k,score)\n",
    "            df.loc[k,score] = sfs\n",
    "    df.to_csv(\"backwardFeatures.csv\",index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_ridge(alpha,X_train,Y_train):\n",
    "    \n",
    "    ridge = Ridge(alpha=1).fit(X_train,Y_train)\n",
    "    \n",
    "    param_grid = dict(alpha=alpha)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=ridge, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid.fit(X_train,Y_train)\n",
    "    \n",
    "    alpha_val = grid.best_estimator_.alpha\n",
    "    \n",
    "    return alpha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(data,y):\n",
    "    \n",
    "    # print(\"------ Ridge Regression ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    alpha = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    best = bestparams_ridge(alpha,X_train,Y_train)\n",
    "    # print(\"Best Alpha:\", best) # best alpha value\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    alpha1 = np.arange(best-10,best+10)\n",
    "    best_alpha = bestparams_ridge(alpha1,X_train,Y_train)\n",
    "    # print(\"Best Alpha after tuning : \", best_alpha)\n",
    "    # Ridge regression with the above best alpha value and the train datasets.\n",
    "    clf = Ridge(alpha=best_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values, \"Confidence\" : confidence, \"Predicted\" : pred, \"Actual\" : Y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_lasso(alpha,X_train,Y_train):\n",
    "    \n",
    "    lasso = Lasso(alpha=1).fit(X_train,Y_train)\n",
    "    \n",
    "    param_grid = dict(alpha=alpha)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid.fit(X_train,Y_train)\n",
    "    \n",
    "    alpha_val = grid.best_estimator_.alpha\n",
    "    \n",
    "    return alpha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(data,y):\n",
    "    \n",
    "    # print(\"------ Lasso Regression ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    alpha = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    best = bestparams_lasso(alpha,X_train,Y_train)\n",
    "    # print(\"Best Alpha:\", best) # best alpha value\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    alpha1 = np.arange(best-10,best+10)\n",
    "    best_alpha = bestparams_lasso(alpha1,X_train,Y_train)\n",
    "    # print(\"Best Alpha after tuning : \", best_alpha)\n",
    "    # Lasso regression with the above best alpha value and the train datasets.\n",
    "    clf = Lasso(alpha=best_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values, \"Confidence\" : confidence, \"Predicted\" : pred, \"Actual\" : Y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_elastic(alphas,l1,X_train,Y_train):\n",
    "    \n",
    "    elastic_net = ElasticNet(alpha=1, l1_ratio=0.2).fit(X_train, Y_train)\n",
    "    param_grid = dict(alpha=alphas, l1_ratio=l1)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=elastic_net, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    \n",
    "    alpha_val = grid_result.best_estimator_.alpha\n",
    "    l1_val = grid_result.best_estimator_.l1_ratio\n",
    "    \n",
    "    return (alpha_val,l1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_regression(data,y):\n",
    "\n",
    "    # print(\"------ Elastic Net Regression ------\")\n",
    "    \n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    \n",
    "    alpha = np.array([0,0.1,0.001,0.0001,1])\n",
    "    l1_ratio = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    \n",
    "    best = bestparams_elastic(alpha,l1_ratio,X_train,Y_train)\n",
    "#     print(\"Best Alpha:\", best[0]) # best alpha value\n",
    "    # print(\"Best l1 - value:\", best[1])\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    \n",
    "    if (best[0] == 0):\n",
    "        clf = ElasticNet(alpha=best[0],l1_ratio = best[1])\n",
    "        clf.fit(X_train, Y_train)\n",
    "    else:\n",
    "        alpha1 = np.arange(best[0]/10,best[0]*10)\n",
    "        best_alpha = bestparams_elastic(alpha1,l1_ratio,X_train,Y_train)\n",
    "        # print(\"Best Alpha after tuning : \", best_alpha[0])\n",
    "        # print(\"Best l1 after tuning : \", best_alpha[1])\n",
    "        clf = ElasticNet(alpha=best_alpha[0],l1_ratio = best_alpha[1])\n",
    "        clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    \n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "    \n",
    "    # coeff_vs_Regularization(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values, \"Confidence\" : confidence, \"Predicted\" : pred, \"Actual\" : Y_test}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_vs_Regularization(X_train,Y_train):\n",
    "    coefs = []\n",
    "    n_alphas = 200\n",
    "    alphas = np.logspace(-10, -2, n_alphas)\n",
    "\n",
    "    for a in alphas:\n",
    "        elastic = ElasticNet(alpha=a)\n",
    "        elastic.fit(X_train, Y_train)\n",
    "        coefs.append(elastic.coef_)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.plot(alphas, coefs)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "    plt.xlabel('alpha(log scale)')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.title('ElasticNet - Coefficients Vs Regularization')\n",
    "    plt.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding results from each set of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Company','Method','Percentage', 'RMSE', 'MAE', 'MSE','Confidence', 'rsquared_adj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {\"500112\" : \"SBIN\" ,\n",
    "\"500325\" : \"RELIANCE INDUSTRIES LTD\",\n",
    "\"532540\" : \"TATA CONSULTANCY SERVICES LTD\" ,\n",
    "\"500209\" : \"INFOSYS LTD\", \n",
    "\"532174\" : \"ICICI BANK LTD\", \n",
    "\"507685\" : \"WIPRO LTD\", \n",
    "\"530965\" : \"INDIAN OIL CORPORATION LTD\", \n",
    "\"500182\" : \"HERO MOTOCORP LTD\", \n",
    "\"532210\" : \"CITY UNION BANK LTD\", \n",
    "\"500180\" : \"HDFC Bank Ltd\",\n",
    "\"500680\" : \"PFIZER LTD\", \n",
    "\"506395\" : \"COROMANDEL iNTERNATIONAL LTD\",\n",
    "\"500770\" : \"TATA CHEMICALS LTD\", \n",
    "\"500085\" : \"CHAMBAL FERTILISERS & CHEMICALS LTD\", \n",
    "\"501425\" : \"BOMBAY BURMAH TRADING CORP.LTD\", \n",
    "\"532899\" : \"KAVERI SEED COMPANY LTD\", \n",
    "\"537291\" : \"NATH BIO-GENES (INDIA) LTD\", \n",
    "\"500790\" : \"NESTLE INDIA LTD\", \n",
    "\"500825\" : \"BRITANNIA INDUSTRIES LTD\", \n",
    "\"533155\" : \"JUBILANT FOODWORKS LTD\", \n",
    "\"533287\" : \"ZEE LEARN LTD\", \n",
    "\"533260\" : \"CAREER POINT LTD\", \n",
    "\"539921\" : \"SHANTI EDUCATIONAL INITIATIVES LTD\", \n",
    "\"542602\" : \"EMBASSY OFFICE PARKS REIT\", \n",
    "\"543217\" : \"MINDSPACE BUSINESS PARKS REIT\", \n",
    "\"543261\" : \"BROOKFIELD INDIA REAL ESTATE TRUST REIT\", \n",
    "\"532538\" : \"ULTRATECH CEMENT LTD\", \n",
    "\"500387\" : \"SHREE CEMENT LTD\", \n",
    "\"500425\" : \"AMBUJA CEMENTS LTD\", \n",
    "\"532689\" : \"PVR LTD\", \n",
    "\"532706\" : \"INOX LEISURE LTD\", \n",
    "\"532163\" : \"SAREGAMA INDIA LTD\", \n",
    "\"524715\" : \"SUN PHARMACEUTICAL INDUSTRIES LTD\", \n",
    "\"532488\" : \"DIVI'S LABORATORIES LTD\",\n",
    "\"500124\" : \"DR.REDDY'S LABORATORIES LTD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"Linear Regression\",\"Lasso Regression\",\"Ridge Regression\",\"Elastic Regression\"]\n",
    "tables = {model:PrettyTable() for model in models}\n",
    "for name,table in tables.items():\n",
    "    table.field_names = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['Company', 'Model', 'Method', 'Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Model, Method, Percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(columns = final_columns)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_table(name,model,result, method, percentage):\n",
    "    values = [name[2 : 8 ] + \"-\" + companies[name[2 : 8]], method, round(percentage, 6)] + [round(v, 6) for k,v in result.items() if not isinstance(v,dict)] + [round(v, 6) for v in result[\"OLS\"].values()]\n",
    "    tables[model].add_row(values)\n",
    "    tables[model].title = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(models, df, column, method, value, name, results):\n",
    "    for model in models:\n",
    "        if (model == \"Linear\"):\n",
    "            model_result = linear_regression(df, column)\n",
    "        elif (model == \"Ridge\"):\n",
    "            model_result = ridge_regression(df, column)\n",
    "        elif (model == \"Lasso\"):\n",
    "            model_result = lasso_regression(df, column)\n",
    "        else:\n",
    "            model_result = elastic_net_regression(df, column)\n",
    "    \n",
    "        print(model + \" Model fitted using columns obtained from feature importance using \" + method + \" : \")\n",
    "        pred = model_result['Predicted']\n",
    "        actual = model_result['Actual']\n",
    "        pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "        pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models_Results\\\\\" + name[2:8] + \"_\" + model + \"FI\" + method + str(value) + \".csv\" , index=False) \n",
    "        same_dir = 0\n",
    "        diff_dir = 0\n",
    "        for a, b in zip(pred, actual) :\n",
    "            if (a * b > 0):\n",
    "                same_dir += 1\n",
    "            else:\n",
    "                diff_dir += 1\n",
    "        print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "        print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "        print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "        percentage = (same_dir / (same_dir + diff_dir))\n",
    "        results[model + \"FI\" + method + str(value)] = (same_dir / (same_dir + diff_dir))\n",
    "        del model_result['Predicted']\n",
    "        del model_result['Actual']\n",
    "        del model_result['OLS']['aic']\n",
    "        del model_result['OLS']['bic']\n",
    "        del model_result['OLS']['fvalue']\n",
    "        create_pretty_table(name ,model + \" Regression\" ,model_result, method + \" \" + value, percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_Coeffiecients(df, name, column, results):\n",
    "    print(\"Features Importance using Coefficients\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    model_linear = LinearRegression(fit_intercept=True)\n",
    "    model_linear.fit(X, Y)\n",
    "    col_coef = list(df.columns)\n",
    "    res_coef = [round(i,6) for i in list(model_linear.coef_)]\n",
    "    rc_coef = list(zip(col_coef, res_coef))\n",
    "    coef_features = []\n",
    "    coef = [0.1]\n",
    "    method = \"Coefficients\"\n",
    "    models = [\"Linear\", \"Ridge\", \"Lasso\", \"Elastic\"]\n",
    "    for cf in coef:\n",
    "        for i in range(len(rc_coef)):\n",
    "            if ((abs(rc_coef[i][1])) > cf):\n",
    "                coef_features.append(rc_coef[i][0])\n",
    "        print(\"Features obtained from coefficients greater than \" + str(cf) + \" : \")\n",
    "        print(\"--------------------------------------\")\n",
    "        print(coef_features)\n",
    "        if (len(coef_features) == 0):\n",
    "            continue\n",
    "        coef_features.append(column)\n",
    "        df_fic = df[coef_features]\n",
    "        fit_model(models, df_fic, column, method, str(cf), name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_PValue(df, name, column, results):\n",
    "    print(\"Features Importance using p-value\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    ols_model = sm.OLS(Y_train, X_train).fit()\n",
    "    col_pval = list(df.columns)\n",
    "    pvals = list(ols_model.pvalues)\n",
    "    pvals_cols = list(zip(col_pval, pvals))\n",
    "    p = [0.02, 0.05, 0.1, 0.2]\n",
    "    method = \"PValue\"\n",
    "    models = [\"Linear\", \"Ridge\", \"Lasso\", \"Elastic\"]\n",
    "    for pv in p:\n",
    "        pval_features = []\n",
    "        for i in range(len(pvals_cols)):\n",
    "            if (pvals_cols[i][1] < pv):\n",
    "                pval_features.append(pvals_cols[i][0])\n",
    "        print(\"Features obtained from p-values less than \" + str(pv) + \" : \")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(pval_features)\n",
    "        if (len(pval_features) == 0):\n",
    "            continue\n",
    "        pval_features.append(column)\n",
    "        df_fip = df[pval_features]\n",
    "        fit_model(models, df_fip, column, method, str(pv), name, results)\n",
    "    print(\"*****************************************************************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_FValues(df, name, column, results):\n",
    "    print(\"Features Importance using f-value\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    fval_cols = X.columns\n",
    "    freg_res = f_regression(X, Y)\n",
    "#     print(freg_res[0])\n",
    "    fvals = freg_res[0]\n",
    "    fc = list(zip(fval_cols, fvals))\n",
    "    f = [1, 10, 100, 1000]\n",
    "    method = \"FValue\"\n",
    "    models = [\"Linear\", \"Ridge\", \"Lasso\", \"Elastic\"]\n",
    "    for fv in f :\n",
    "        fval_features = []\n",
    "        for i in range(len(fc)):\n",
    "            if ((abs(fc[i][1])) > fv):\n",
    "                fval_features.append(fc[i][0])\n",
    "        print(\"Features obtained from f-values greater than \" + str(fv) + \" : \")\n",
    "        print(\"--------------------------------------\")\n",
    "        print(fval_features)\n",
    "        if (len(fval_features) == 0):\n",
    "            continue\n",
    "        fval_features.append(column)\n",
    "        df_fif = df[fval_features]\n",
    "        fit_model(models, df_fif, column, method, str(fv), name, results)\n",
    "    print(\"*****************************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_ForwardSelection(df1, name, column, results):\n",
    "    print(\"Features Importance using Forward Selection Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"ForwardSelection\"\n",
    "    models = [\"Linear\", \"Ridge\", \"Lasso\", \"Elastic\"]\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    forward_features = forward_selection(X,Y)\n",
    "    print(\"Features obtained from Forward Selection method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(forward_features)\n",
    "    if (len(forward_features) != 0):\n",
    "        forward_features.append(column)\n",
    "        df_fs = df1[forward_features]\n",
    "        fit_model(models, df_fs, column, method, '', name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_BackwardElimination(df1, name, column, results):\n",
    "    print(\"Features Importance using Backward Elimination Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"BackwardElimination\"\n",
    "    models = [\"Linear\", \"Ridge\", \"Lasso\", \"Elastic\"]\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    backward_features = backward_elimination(X,Y)\n",
    "    print(\"Features obtained from Backward Elimination method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(backward_features)\n",
    "    if (len(backward_features) != 0):\n",
    "        backward_features.append(column)\n",
    "        df_be = df1[backward_features]\n",
    "        fit_model(models, df_be, column, method, '', name, results)\n",
    "#     lfs_res = linear_regression_backward_selection(df1, column)\n",
    "#     pred = lfs_res['Predicted']\n",
    "#     actual = lfs_res['Actual']\n",
    "#     pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "#                columns =['Predicted Values', 'Actual Values'])\n",
    "#     pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFI_BE_\" + name + \".csv\" , index=False) \n",
    "#     same_dir = 0\n",
    "#     diff_dir = 0\n",
    "#     for a, b in zip(pred, actual) :\n",
    "#         if (a * b > 0):\n",
    "#             same_dir += 1\n",
    "#         else:\n",
    "#             diff_dir += 1\n",
    "#     print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "#     print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "#     print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "#     results[\"FI_BE\"] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_each_set(data, name, final_df):\n",
    "    df = pre_process_data(data, 60)\n",
    "    column = \"Next Day Close Price GR\"\n",
    "    (df1, column) = dependent_column(df, column)\n",
    "    results = {}\n",
    "    get_results_from_FI_Coeffiecients(df1, name, column, results)\n",
    "    get_results_from_FI_PValue(df1, name, column, results)\n",
    "    get_results_from_FI_ForwardSelection(df1, name, column, results)\n",
    "    get_results_from_FI_BackwardElimination(df1, name, column, results)\n",
    "    get_results_from_FI_FValues(df1, name, column, results)\n",
    "#     print(results)\n",
    "#     print(len(results))\n",
    "    linear = {k : v for (k, v) in results.items() if (\"Linear\" in k)}\n",
    "    ridge = {k : v for (k, v) in results.items() if (\"Ridge\" in k)}\n",
    "    lasso = {k : v for (k, v) in results.items() if (\"Lasso\" in k)}\n",
    "    elastic = {k : v for (k, v) in results.items() if (\"Elastic\" in k)}\n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1])\n",
    "    sorted_linear = sorted(linear.items(), key=lambda item: item[1])\n",
    "    sorted_ridge = sorted(ridge.items(), key=lambda item: item[1])\n",
    "    sorted_lasso = sorted(lasso.items(), key=lambda item: item[1])\n",
    "    sorted_elastic = sorted(elastic.items(), key=lambda item: item[1])\n",
    "    linear_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'Linear Regression', 'Method' : sorted_linear[-1][0], 'Percentage' : sorted_linear[-1][1]}\n",
    "    ridge_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'Ridge Regression', 'Method' : sorted_ridge[-1][0], 'Percentage' : sorted_ridge[-1][1]}\n",
    "    lasso_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'Lasso Regression', 'Method' : sorted_lasso[-1][0], 'Percentage' : sorted_lasso[-1][1]}\n",
    "    elastic_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'Elastic Net Regression', 'Method' : sorted_elastic[-1][0], 'Percentage' : sorted_elastic[-1][1]}\n",
    "    final_df = final_df.append(linear_row, ignore_index = True)\n",
    "    final_df = final_df.append(ridge_row, ignore_index = True)\n",
    "    final_df = final_df.append(lasso_row, ignore_index = True)\n",
    "    final_df = final_df.append(elastic_row, ignore_index = True)\n",
    "    print(\"Maximum correct direction values are obtained for {} with a percentage of {}.\".format(sorted_results[-1][0], sorted_results[-1][1]))\n",
    "    print(\"Maximum correct direction values for Linear Model are obtained for {} with a percentage of {}.\".format(sorted_linear[-1][0], sorted_linear[-1][1]))\n",
    "    print(\"Maximum correct direction values for Ridge Model are obtained for {} with a percentage of {}.\".format(sorted_ridge[-1][0], sorted_ridge[-1][1]))\n",
    "    print(\"Maximum correct direction values for Lasso Model are obtained for {} with a percentage of {}.\".format(sorted_lasso[-1][0], sorted_lasso[-1][1]))\n",
    "    print(\"Maximum correct direction values for Elastic Model are obtained for {} with a percentage of {}.\".format(sorted_elastic[-1][0], sorted_elastic[-1][1]))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For stock :  500085\n",
      "#################################################################################################################\n",
      "Features Importance using Coefficients\n",
      "*****************************************************************************************\n",
      "Features obtained from coefficients greater than 0.1 : \n",
      "--------------------------------------\n",
      "[]\n",
      "*****************************************************************************************\n",
      "Features Importance using p-value\n",
      "*****************************************************************************************\n",
      "Features obtained from p-values less than 0.02 : \n",
      "-------------------------------------------------\n",
      "[]\n",
      "Features obtained from p-values less than 0.05 : \n",
      "-------------------------------------------------\n",
      "[]\n",
      "Features obtained from p-values less than 0.1 : \n",
      "-------------------------------------------------\n",
      "[]\n",
      "Features obtained from p-values less than 0.2 : \n",
      "-------------------------------------------------\n",
      "['Deliverable Quantity GR', '% Deli. Qty to Traded Qty GR']\n",
      "Linear Model fitted using columns obtained from feature importance using PValue : \n",
      "Values in Same direction -----> -----> 393\n",
      "Values in Opposite direction <----- ----->  425\n",
      "Percentage of correct direction :  0.480440097799511\n",
      "Ridge Model fitted using columns obtained from feature importance using PValue : \n",
      "Values in Same direction -----> -----> 390\n",
      "Values in Opposite direction <----- ----->  428\n",
      "Percentage of correct direction :  0.4767726161369193\n",
      "Lasso Model fitted using columns obtained from feature importance using PValue : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "Elastic Model fitted using columns obtained from feature importance using PValue : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "*****************************************************************************************\n",
      "Features Importance using Forward Selection Method\n",
      "*****************************************************************************************\n",
      "Features obtained from Forward Selection method : \n",
      "--------------------------------------\n",
      "['Beta GR']\n",
      "Linear Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Values in Same direction -----> -----> 410\n",
      "Values in Opposite direction <----- ----->  408\n",
      "Percentage of correct direction :  0.5012224938875306\n",
      "Ridge Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Values in Same direction -----> -----> 408\n",
      "Values in Opposite direction <----- ----->  410\n",
      "Percentage of correct direction :  0.49877750611246946\n",
      "Lasso Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "Elastic Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "*****************************************************************************************\n",
      "Features Importance using Backward Elimination Method\n",
      "*****************************************************************************************\n",
      "Features obtained from Backward Elimination method : \n",
      "--------------------------------------\n",
      "['Beta GR']\n",
      "Linear Model fitted using columns obtained from feature importance using BackwardElimination : \n",
      "Values in Same direction -----> -----> 410\n",
      "Values in Opposite direction <----- ----->  408\n",
      "Percentage of correct direction :  0.5012224938875306\n",
      "Ridge Model fitted using columns obtained from feature importance using BackwardElimination : \n",
      "Values in Same direction -----> -----> 408\n",
      "Values in Opposite direction <----- ----->  410\n",
      "Percentage of correct direction :  0.49877750611246946\n",
      "Lasso Model fitted using columns obtained from feature importance using BackwardElimination : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "Elastic Model fitted using columns obtained from feature importance using BackwardElimination : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "*****************************************************************************************\n",
      "Features Importance using f-value\n",
      "*****************************************************************************************\n",
      "Features obtained from f-values greater than 1 : \n",
      "--------------------------------------\n",
      "['Open Price GR', 'Low Price GR', 'Spread High-Low GR', 'Spread Close-Open GR', 'Alpha GR', 'Beta GR']\n",
      "Linear Model fitted using columns obtained from feature importance using FValue : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n",
      "Ridge Model fitted using columns obtained from feature importance using FValue : \n",
      "Values in Same direction -----> -----> 414\n",
      "Values in Opposite direction <----- ----->  404\n",
      "Percentage of correct direction :  0.5061124694376528\n",
      "Lasso Model fitted using columns obtained from feature importance using FValue : \n",
      "Values in Same direction -----> -----> 407\n",
      "Values in Opposite direction <----- ----->  411\n",
      "Percentage of correct direction :  0.49755501222493886\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-c2027366297b>\u001b[0m in \u001b[0;36mget_results_from_each_set\u001b[1;34m(data, name, final_df)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mget_results_from_FI_ForwardSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mget_results_from_FI_BackwardElimination\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mget_results_from_FI_FValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#     print(results)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     print(len(results))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-41b73eb11cb9>\u001b[0m in \u001b[0;36mget_results_from_FI_FValues\u001b[1;34m(df, name, column, results)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfval_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdf_fif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfval_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_fif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*****************************************************************************************\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-cd60a4db8dd2>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(models, df, column, method, value, name, results)\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmodel_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasso_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mmodel_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melastic_net_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" Model fitted using columns obtained from feature importance using \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" : \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-768620512647>\u001b[0m in \u001b[0;36melastic_net_regression\u001b[1;34m(data, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0malpha1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mbest_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbestparams_elastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;31m# print(\"Best Alpha after tuning : \", best_alpha[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# print(\"Best l1 after tuning : \", best_alpha[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-29b714d2e58d>\u001b[0m in \u001b[0;36mbestparams_elastic\u001b[1;34m(alphas, l1, X_train, Y_train)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melastic_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0malpha_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0mX_copied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             X, y = self._validate_data(X, y, accept_sparse='csc',\n\u001b[0m\u001b[0;32m    772\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m                                        \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'fc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2241\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2242\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock\")):\n",
    "    if (filename.startswith(\"gr\")):\n",
    "        df_linear = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\" + filename))\n",
    "        name = os.path.join(path, \"Data\\Stock\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = name[2 : 8]\n",
    "#         orig_stdout = sys.stdout\n",
    "#         sys.stdout = open(\"gr\" + stock + \"res.txt\", \"w\")\n",
    "        fd_df = pd.DataFrame(columns = final_columns)\n",
    "        print(\"For stock : \", stock)\n",
    "        print(\"#################################################################################################################\")\n",
    "        f_df = get_results_from_each_set(df_linear, name, fd_df)\n",
    "        final_df = final_df.append(f_df, ignore_index = True)\n",
    "        print(\"#################################################################################################################\")\n",
    "#         sys.stdout.close()\n",
    "#         sys.stdout = orig_stdout\n",
    "final_df = final_df.sort_values(by = ['Company', 'Percentage'], ascending = [True, False])\n",
    "final_df.to_csv('C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models_Results\\\\df_Final_Results.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                              Linear Regression                                                              |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "|                  Company                   |        Method        | Percentage |   RMSE   |   MAE    |   MSE    | Confidence | rsquared_adj |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |      PValue 0.2      |  0.48044   | 0.030303 | 0.020423 | 0.000918 | -0.001206  |  -0.000534   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |  ForwardSelection    |  0.501222  | 0.029949 | 0.020288 | 0.000897 |  0.022021  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD | BackwardElimination  |  0.501222  | 0.029949 | 0.020288 | 0.000897 |  0.022021  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |       FValue 1       |  0.497555  | 0.029907 | 0.020276 | 0.000894 |  0.024759  |  -0.000665   |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                               Lasso Regression                                                              |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "|                  Company                   |        Method        | Percentage |   RMSE   |   MAE    |   MSE    | Confidence | rsquared_adj |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |      PValue 0.2      |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |  -0.000534   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |  ForwardSelection    |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD | BackwardElimination  |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |       FValue 1       |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |  -0.000665   |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                               Ridge Regression                                                              |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "|                  Company                   |        Method        | Percentage |   RMSE   |   MAE    |   MSE    | Confidence | rsquared_adj |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |      PValue 0.2      |  0.476773  | 0.030303 | 0.020423 | 0.000918 | -0.001205  |  -0.000534   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |  ForwardSelection    |  0.498778  | 0.031687 | 0.020667 | 0.001004 | -0.094739  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD | BackwardElimination  |  0.498778  | 0.031687 | 0.020667 | 0.001004 | -0.094739  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |       FValue 1       |  0.506112  | 0.031296 | 0.020597 | 0.000979 | -0.067894  |  -0.000665   |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|                                                              Elastic Regression                                                             |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "|                  Company                   |        Method        | Percentage |   RMSE   |   MAE    |   MSE    | Confidence | rsquared_adj |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |      PValue 0.2      |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |  -0.000534   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD |  ForwardSelection    |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |   0.000419   |\n",
      "| 500085-CHAMBAL FERTILISERS & CHEMICALS LTD | BackwardElimination  |  0.497555  | 0.030302 | 0.020418 | 0.000918 | -0.001148  |   0.000419   |\n",
      "+--------------------------------------------+----------------------+------------+----------+----------+----------+------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "for name,table in tables.items():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Model, Method, Percentage]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_stdout = sys.stdout\n",
    "# sys.stdout = open(\"500112res.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Stock\\\\gr500112.csv\"\n",
    "# df_lin = pd.read_csv(path)\n",
    "# name = path.split(\"\\\\\")[-1]\n",
    "# stock = name[2 : 8]\n",
    "# print(\"For stock : \", stock)\n",
    "# print(\"#################################################################################################################\")\n",
    "# get_results_from_each_set(df_lin, name)\n",
    "# print(\"#################################################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.stdout.close()\n",
    "# sys.stdout=orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
