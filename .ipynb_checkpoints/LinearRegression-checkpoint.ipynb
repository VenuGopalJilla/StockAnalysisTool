{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: text-to-image in c:\\users\\venu\\anaconda3\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\venu\\anaconda3\\lib\\site-packages (from text-to-image) (7.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install text-to-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "import statsmodels.api as sm\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from prettytable import PrettyTable\n",
    "import time \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patches as patches\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import sys\n",
    "import text_to_image\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if ((null_threshold * total / 100) < data[col].isnull().sum()):\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing columns based on dependent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    cols = [col for col in data.columns if (\"next\" not in col.lower() and col.lower().endswith(\"gr\"))]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_Regression(X_train,Y_train,cols):\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    ols_model = sm.OLS(Y_train, X_train).fit()\n",
    "#     print(list(zip(list(cols),ols_model.pvalues)))\n",
    "    rsquared_adj = ols_model.rsquared_adj\n",
    "    aic = ols_model.aic\n",
    "    bic = ols_model.bic\n",
    "    fvalue = ols_model.fvalue\n",
    "    return {\"rsquared_adj\":rsquared_adj,\"aic\":aic,\"bic\":bic,\"fvalue\":fvalue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(data, y):\n",
    "    # print(\"------ Linear Regression ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    model = LinearRegression(fit_intercept = True)  \n",
    "    model.fit(X_train, Y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    confidence = model.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train,X.columns)\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values, \"Confidence\" : confidence, \"Predicted\" : pred, \"Actual\" : Y_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression with forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]]).astype(float)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_forward_selection(data,y):\n",
    "    # print(\"------ Linear Regression Forward Selection ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    forward_features = forward_selection(X,Y)\n",
    "    print(\"Features obtained from Forward Selection : \")\n",
    "    print(forward_features)\n",
    "    return linear_regression(data[forward_features+[y]],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression with backward elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features]).astype(float)\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_backward_selection(data,y):\n",
    "    # print(\"------ Linear Regression Backward Selection ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    backward_features = backward_elimination(X,Y)\n",
    "    print(\"Features obtained from Backward Elimination : \")\n",
    "    print(backward_features)\n",
    "    return linear_regression(data[backward_features+[y]],y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inbuilt Forward Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection_inbuilt(X,Y,k,score):\n",
    "    sfs = SFS(LinearRegression(),k_features=k,forward=True,floating=False,scoring = score,cv = 0)\n",
    "    sfs.fit(X, Y)\n",
    "    lst = list(sfs.k_feature_names_)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_forward_selection_inbuit(data,y):\n",
    "    # print(\"------ Linear Regression Forward Selection Inbuilt ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    scores = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error',\n",
    "                  'neg_root_mean_squared_error','neg_median_absolute_error','r2']\n",
    "    df = pd.DataFrame(columns=scores,index=range(1,data.shape[1]+1))\n",
    "    for k in range(1,data.shape[1]+1):\n",
    "        for score in scores:\n",
    "            sfs = forward_selection_inbuilt(X,Y,k,score)\n",
    "            df.loc[k,score] = sfs\n",
    "    df.to_csv(\"forwardFeatures.csv\",index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inbuilt Backward Elimination Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection_inbuilt(X,Y,k,score):\n",
    "    sfs = SFS(LinearRegression(),k_features=k,forward=False,floating=False,scoring = score,cv = 0)\n",
    "    sfs.fit(X, Y)\n",
    "    lst = list(sfs.k_feature_names_)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_backward_selection_inbuit(data,y):\n",
    "    # print(\"------ Linear Regression Backward Selection Inbuilt ------\")\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    scores = ['explained_variance','max_error','neg_mean_absolute_error','neg_mean_squared_error',\n",
    "                  'neg_root_mean_squared_error','neg_median_absolute_error','r2']\n",
    "    df = pd.DataFrame(columns=scores,index=range(1,data.shape[1]+1))\n",
    "    for k in range(1,data.shape[1]+1):\n",
    "        for score in scores:\n",
    "            sfs = backward_selection_inbuilt(X,Y,k,score)\n",
    "            df.loc[k,score] = sfs\n",
    "    df.to_csv(\"backwardFeatures.csv\",index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_ridge(alpha,X_train,Y_train):\n",
    "    \n",
    "    ridge = Ridge(alpha=1).fit(X_train,Y_train)\n",
    "    \n",
    "    param_grid = dict(alpha=alpha)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=ridge, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid.fit(X_train,Y_train)\n",
    "    \n",
    "    alpha_val = grid.best_estimator_.alpha\n",
    "    \n",
    "    return alpha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(data,y):\n",
    "    \n",
    "    # print(\"------ Ridge Regression ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    alpha = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    best = bestparams_ridge(alpha,X_train,Y_train)\n",
    "    # print(\"Best Alpha:\", best) # best alpha value\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    alpha1 = np.arange(best-10,best+10)\n",
    "    best_alpha = bestparams_ridge(alpha1,X_train,Y_train)\n",
    "    # print(\"Best Alpha after tuning : \", best_alpha)\n",
    "    # Ridge regression with the above best alpha value and the train datasets.\n",
    "    clf = Ridge(alpha=best_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_lasso(alpha,X_train,Y_train):\n",
    "    \n",
    "    lasso = Lasso(alpha=1).fit(X_train,Y_train)\n",
    "    \n",
    "    param_grid = dict(alpha=alpha)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid.fit(X_train,Y_train)\n",
    "    \n",
    "    alpha_val = grid.best_estimator_.alpha\n",
    "    \n",
    "    return alpha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(data,y):\n",
    "    \n",
    "    # print(\"------ Lasso Regression ------\")\n",
    "\n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    alpha = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    best = bestparams_lasso(alpha,X_train,Y_train)\n",
    "    # print(\"Best Alpha:\", best) # best alpha value\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    alpha1 = np.arange(best-10,best+10)\n",
    "    best_alpha = bestparams_lasso(alpha1,X_train,Y_train)\n",
    "    # print(\"Best Alpha after tuning : \", best_alpha)\n",
    "    # Lasso regression with the above best alpha value and the train datasets.\n",
    "    clf = Lasso(alpha=best_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestparams_elastic(alphas,l1,X_train,Y_train):\n",
    "    \n",
    "    elastic_net = ElasticNet(alpha=1, l1_ratio=0.2).fit(X_train, Y_train)\n",
    "    param_grid = dict(alpha=alphas, l1_ratio=l1)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=elastic_net, param_grid=param_grid, scoring='r2')\n",
    "    \n",
    "    grid_result = grid.fit(X_train, Y_train)\n",
    "    \n",
    "    alpha_val = grid_result.best_estimator_.alpha\n",
    "    l1_val = grid_result.best_estimator_.l1_ratio\n",
    "    \n",
    "    return (alpha_val,l1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net_regression(data,y):\n",
    "\n",
    "    # print(\"------ Elastic Net Regression ------\")\n",
    "    \n",
    "    X = data[data.columns[:-1]]\n",
    "    Y = data[y].values\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # selection of alpha value from the respective array values\n",
    "    \n",
    "    alpha = np.array([0,0.1,0.001,0.0001,1])\n",
    "    l1_ratio = np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    \n",
    "    best = bestparams_elastic(alpha,l1_ratio,X_train,Y_train)\n",
    "    # print(\"Best Alpha:\", best[0]) # best alpha value\n",
    "    # print(\"Best l1 - value:\", best[1])\n",
    "    \n",
    "    # Re-selecting the alpha value based on the above selected alpha value\n",
    "    \n",
    "    alpha1 = np.arange(best[0]/10,best[0]*10)\n",
    "    best_alpha = bestparams_elastic(alpha1,l1_ratio,X_train,Y_train)\n",
    "    # print(\"Best Alpha after tuning : \", best_alpha[0])\n",
    "    # print(\"Best l1 after tuning : \", best_alpha[1])\n",
    "    clf = ElasticNet(alpha=best_alpha[0],l1_ratio = best_alpha[1])\n",
    "    clf.fit(X_train, Y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    confidence = clf.score(X_test, Y_test)\n",
    "    \n",
    "    rmse = sqrt(metrics.mean_squared_error(Y_test, pred))\n",
    "    mae = metrics.mean_absolute_error(Y_test, pred)\n",
    "    mse = metrics.mean_squared_error(Y_test, pred)\n",
    "    ols_values = OLS_Regression(X_train,Y_train)\n",
    "    \n",
    "    # coeff_vs_Regularization(X_train,Y_train)\n",
    "\n",
    "    return {\"root_mean_squared_error\":rmse,\"mean_absolute_error\":mae,\"mean_squared_error\":mse,\"OLS\":ols_values}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_vs_Regularization(X_train,Y_train):\n",
    "    coefs = []\n",
    "    n_alphas = 200\n",
    "    alphas = np.logspace(-10, -2, n_alphas)\n",
    "\n",
    "    for a in alphas:\n",
    "        elastic = ElasticNet(alpha=a)\n",
    "        elastic.fit(X_train, Y_train)\n",
    "        coefs.append(elastic.coef_)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.plot(alphas, coefs)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "    plt.xlabel('alpha(log scale)')\n",
    "    plt.ylabel('Coefficients')\n",
    "    plt.title('ElasticNet - Coefficients Vs Regularization')\n",
    "    plt.axis('tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding results from each set of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_Coeffiecients(df, name, column, results):\n",
    "    print(\"Features Importance using Coefficients\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    model_linear = LinearRegression(fit_intercept=True)\n",
    "    model_linear.fit(X, Y)\n",
    "    col_coef = list(df.columns)\n",
    "    res_coef = [round(i,6) for i in list(model_linear.coef_)]\n",
    "    rc_coef = list(zip(col_coef, res_coef))\n",
    "    coef_features = []\n",
    "    coef = [0.1]\n",
    "    for cf in coef:\n",
    "        for i in range(len(rc_coef)):\n",
    "            if ((abs(rc_coef[i][1])) > cf):\n",
    "                coef_features.append(rc_coef[i][0])\n",
    "        print(\"Features obtained from coefficients greater than \" + str(cf) + \" : \")\n",
    "        print(\"--------------------------------------\")\n",
    "        print(coef_features)\n",
    "        if (len(coef_features) == 0):\n",
    "            continue\n",
    "        coef_features.append(column)\n",
    "        df_fic = df[coef_features]\n",
    "        linear_model_result = linear_regression(df_fic, column)\n",
    "        print(\"Linear Model fitted using columns obtained from feature importance using coefficients : \")\n",
    "        pred = linear_model_result['Predicted']\n",
    "        actual = linear_model_result['Actual']\n",
    "        pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "        pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFIC\" + str(cf) + \"_\" + name + \".csv\" , index=False) \n",
    "        same_dir = 0\n",
    "        diff_dir = 0\n",
    "        for a, b in zip(pred, actual) :\n",
    "            if (a * b > 0):\n",
    "                same_dir += 1\n",
    "            else:\n",
    "                diff_dir += 1\n",
    "        print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "        print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "        print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "        results[\"LinearFIC\" + str(cf)] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_PValue(df, name, column, results):\n",
    "    print(\"Features Importance using p-value\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    X_train = np.array(X_train, dtype=float)\n",
    "    ols_model = sm.OLS(Y_train, X_train).fit()\n",
    "    col_pval = list(df.columns)\n",
    "    pvals = list(ols_model.pvalues)\n",
    "    pvals_cols = list(zip(col_pval, pvals))\n",
    "    p = [0.02, 0.05, 0.1, 0.2]\n",
    "    for pv in p:\n",
    "        pval_features = []\n",
    "        for i in range(len(pvals_cols)):\n",
    "            if (pvals_cols[i][1] < pv):\n",
    "                pval_features.append(pvals_cols[i][0])\n",
    "        print(\"Features obtained from p-values less than \" + str(pv) + \" : \")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(pval_features)\n",
    "        if (len(pval_features) == 0):\n",
    "            continue\n",
    "        pval_features.append(column)\n",
    "        df_fip = df[pval_features]\n",
    "        linear_model_result = linear_regression(df_fip, column)\n",
    "        print(\"Linear Model fitted using columns obtained from feature importance using p-values : \")\n",
    "        pred = linear_model_result['Predicted']\n",
    "        actual = linear_model_result['Actual']\n",
    "        pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "        pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFIP\" + str(pv) + \"_\" + name + \".csv\" , index=False) \n",
    "        same_dir = 0\n",
    "        diff_dir = 0\n",
    "        for a, b in zip(pred, actual) :\n",
    "            if (a * b > 0):\n",
    "                same_dir += 1\n",
    "            else:\n",
    "                diff_dir += 1\n",
    "        print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "        print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "        print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "        results[\"LinearFIP\" + str(pv)] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_FValues(df, name, column, results):\n",
    "    print(\"Features Importance using f-value\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    fval_cols = X.columns\n",
    "    freg_res = f_regression(X, Y)\n",
    "#     print(freg_res[0])\n",
    "    fvals = freg_res[0]\n",
    "    fc = list(zip(fval_cols, fvals))\n",
    "    f = [1, 10, 100, 1000]\n",
    "    for fv in f :\n",
    "        fval_features = []\n",
    "        for i in range(len(fc)):\n",
    "            if ((abs(fc[i][1])) > fv):\n",
    "                fval_features.append(fc[i][0])\n",
    "        print(\"Features obtained from f-values greater than \" + str(fv) + \" : \")\n",
    "        print(\"--------------------------------------\")\n",
    "        print(fval_features)\n",
    "        if (len(fval_features) == 0):\n",
    "            continue\n",
    "        fval_features.append(column)\n",
    "        df_fif = df[fval_features]\n",
    "        linear_model_result = linear_regression(df_fif, column)\n",
    "        print(\"Linear Model fitted using columns obtained from feature importance using f-values : \")\n",
    "        pred = linear_model_result['Predicted']\n",
    "        actual = linear_model_result['Actual']\n",
    "        pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "        pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFIF\" + str(fv) + \"_\" + name + \".csv\" , index=False) \n",
    "        same_dir = 0\n",
    "        diff_dir = 0\n",
    "        for a, b in zip(pred, actual) :\n",
    "            if (a * b > 0):\n",
    "                same_dir += 1\n",
    "            else:\n",
    "                diff_dir += 1\n",
    "        print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "        print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "        print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "        results[\"LinearFIF\" + str(fv)] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_ForwardSelection(df1, name, column, results):\n",
    "    print(\"Features Importance using Forward Selection Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    lfs_res = linear_regression_forward_selection(df1, column)\n",
    "    pred = lfs_res['Predicted']\n",
    "    actual = lfs_res['Actual']\n",
    "    pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "               columns =['Predicted Values', 'Actual Values'])\n",
    "    pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFI_FS_\" + name + \".csv\" , index=False) \n",
    "    same_dir = 0\n",
    "    diff_dir = 0\n",
    "    for a, b in zip(pred, actual) :\n",
    "        if (a * b > 0):\n",
    "            same_dir += 1\n",
    "        else:\n",
    "            diff_dir += 1\n",
    "    print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "    print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "    print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "    results[\"FI_FS\"] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_BackwardElimination(df1, name, column, results):\n",
    "    print(\"Features Importance using Backward Elimination Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    lfs_res = linear_regression_backward_selection(df1, column)\n",
    "    pred = lfs_res['Predicted']\n",
    "    actual = lfs_res['Actual']\n",
    "    pred_actual = pd.DataFrame(list(zip(pred, actual)), \n",
    "               columns =['Predicted Values', 'Actual Values'])\n",
    "    pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\Models Results\\\\LinearFI_BE_\" + name + \".csv\" , index=False) \n",
    "    same_dir = 0\n",
    "    diff_dir = 0\n",
    "    for a, b in zip(pred, actual) :\n",
    "        if (a * b > 0):\n",
    "            same_dir += 1\n",
    "        else:\n",
    "            diff_dir += 1\n",
    "    print(\"Values in Same direction -----> ----->\", same_dir)\n",
    "    print(\"Values in Opposite direction <----- -----> \", diff_dir)\n",
    "    print(\"Percentage of correct direction : \", (same_dir / (same_dir + diff_dir)))\n",
    "    results[\"FI_BE\"] = (same_dir / (same_dir + diff_dir))\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_each_set(data, name):\n",
    "    df = pre_process_data(data, 60)\n",
    "    column = \"Next Day Close Price GR\"\n",
    "    (df1, column) = dependent_column(df, column)\n",
    "    results = {}\n",
    "    get_results_from_FI_Coeffiecients(df1, name, column, results)\n",
    "    get_results_from_FI_PValue(df1, name, column, results)\n",
    "    get_results_from_FI_ForwardSelection(df1, name, column, results)\n",
    "    get_results_from_FI_BackwardElimination(df1, name, column, results)\n",
    "    get_results_from_FI_FValues(df1, name, column, results)\n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1])\n",
    "    print(\"Maximum correct direction values are obtained for {} with a percentage of {}.\".format(sorted_results[-1][0], sorted_results[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock\")):\n",
    "    if (filename.startswith(\"gr\")):\n",
    "        df_linear = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\" + filename))\n",
    "        name = os.path.join(path, \"Data\\Stock\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = name[2 : 8]\n",
    "        orig_stdout = sys.stdout\n",
    "        sys.stdout = open(\"gr\" + stock + \"res.txt\", \"w\")\n",
    "        print(\"For stock : \", stock)\n",
    "        print(\"#################################################################################################################\")\n",
    "        get_results_from_each_set(df_linear, name)\n",
    "        print(\"#################################################################################################################\")\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_stdout = sys.stdout\n",
    "# sys.stdout = open(\"500112res.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Stock\\\\gr500112.csv\"\n",
    "# df_lin = pd.read_csv(path)\n",
    "# name = path.split(\"\\\\\")[-1]\n",
    "# stock = name[2 : 8]\n",
    "# print(\"For stock : \", stock)\n",
    "# print(\"#################################################################################################################\")\n",
    "# get_results_from_each_set(df_lin, name)\n",
    "# print(\"#################################################################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.stdout.close()\n",
    "# sys.stdout=orig_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
