{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a88f342-ed29-4f26-8a98-54bdc022db76",
    "_uuid": "90f7dd7c-8106-4840-96e1-0b48629bca23",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import time \n",
    "import re\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import traceback\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cfe90cf4-9ab2-4b01-b935-4bd3bc0789ac",
    "_uuid": "619c171b-5a37-4430-bb2e-aff9bcfcc8e3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_data(df, null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "\n",
    "    df.drop(columns=['Date'], axis=1, inplace=True)\n",
    "    total = df.shape[0]\n",
    "    for col in df.columns:\n",
    "        if null_threshold * total / 100 < df[col].isnull().sum():\n",
    "            df.drop(columns=[col], axis=1, inplace=True)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a5a0f4b9-484f-4917-8486-8f252449d5ca",
    "_uuid": "b245b9c1-1495-4cff-a541-cf459a62f0cc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def error_metrics(y_true, y_pred):\n",
    "    rmse = metrics.mean_squared_error(y_true, y_pred) ** 0.5\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2_score = metrics.r2_score(y_true, y_pred)\n",
    "    return {\"root_mean_squared_error\": rmse, \"mean_absolute_error\": mae, \"mean_squared_error\": mse,\"r2_score\":r2_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8f515f59-69d7-4257-a7b0-4f64abc843a8",
    "_uuid": "5e7358bc-a5f6-4009-9c8c-eee159f95103",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(X,Y,t):\n",
    "    tr = int(len(X)*t)\n",
    "    tt = len(X) - tr\n",
    "    xtr = X[:tr]\n",
    "    xtt = X[tr:tr+tt]\n",
    "    ytr = Y[:tr]\n",
    "    ytt = Y[tr:tr+tt]\n",
    "    return (xtr,xtt,ytr,ytt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "99e86bf8-27ea-4570-9262-f5d5337cea24",
    "_uuid": "e9491988-3c2d-4f22-b4aa-e4fa5d8e75d0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_next_columns(df,column):\n",
    "    cols = [col for col in df.columns if \"next\" not in col.lower()]\n",
    "    cols.append(column)\n",
    "    df = df[cols]\n",
    "    return (df, column)\n",
    "\n",
    "def remove_cp_columns(df):\n",
    "    cols = [col for col in df.columns if not col.lower().startswith(\"cp\")]\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "def remove_previous_columns(df,column):\n",
    "    cols = [col for col in df.columns if not col.lower().startswith(\"previous\")]\n",
    "    cols.append(column)\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "def remove_max_avg_min_columns(df):\n",
    "    cols = [col for col in df.columns if not (col.lower().startswith(\"max\") or col.lower().startswith(\"avg\") or col.lower().startswith(\"min\"))]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_dataset(X,Y,t):\n",
    "    tr = int(len(X)*t)\n",
    "    tt = len(X) - tr\n",
    "    xtr = X[:tr]\n",
    "    xtt = X[tr:tr+tt]\n",
    "    ytr = Y[:tr]\n",
    "    ytt = Y[tr:tr+tt]\n",
    "    return (xtr,xtt,ytr,ytt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da676a9c-28bb-4b85-81b4-7ff7f9dd571a",
    "_uuid": "dbfd39f7-4c31-4f2a-a046-11f7b37e8cf3",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_linear(X_train, X_test, Y_train, Y_test,num,col):\n",
    "    linear_pipeline = Pipeline([(\"feature_selection\",SequentialFeatureSelector(LinearRegression(),n_jobs=None,n_features_to_select=num)),(\"linear_regression\",LinearRegression())])\n",
    "    linear_pipeline.fit(X_train,Y_train)\n",
    "    Y_pred = linear_pipeline.predict(X_test)\n",
    "    result = error_metrics(Y_test,Y_pred)\n",
    "    selected_features = X_train.columns[linear_pipeline[\"feature_selection\"].get_support()].tolist()\n",
    "    result.update({\"selected_features\":selected_features})\n",
    "    result.update({\"numoffeatures\":len(selected_features)})\n",
    "    result.update({\"predicted_column\":col})\n",
    "    result.update({\"model\":\"linear\"})\n",
    "    result.update({\"actual\":Y_test.values.tolist()})\n",
    "    result.update({\"predicted\":Y_pred.tolist()})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20f5b9c1-b069-47e7-996e-3bedc2b554c5",
    "_uuid": "6d4d14c1-2a5d-4080-8175-890cce7c37ed",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_models(df,col):\n",
    "    ref = df.copy()\n",
    "    days = int(re.findall(r\"\\d+\",col)[0])\n",
    "    start = df['Date'].iloc[0] + datetime.timedelta(days = days)\n",
    "    end = df['Date'].iloc[-1] - datetime.timedelta(days = days)\n",
    "    df  = df[df.Date.between(start,end)]\n",
    "    df = pre_process_data(df, 60)\n",
    "    df[df.columns] = (df[df.columns].astype(str)).apply(pd.to_numeric, errors='coerce')\n",
    "    df,column = remove_next_columns(df,col)\n",
    "    X = df.drop(columns=[column])\n",
    "    Y = df[column]\n",
    "    X_train, X_test, Y_train, Y_test = split_dataset(X, Y,0.70)\n",
    "    num = 0.33\n",
    "    linres = run_linear(X_train, X_test, Y_train, Y_test,num,column)\n",
    "    linres.update({\"close\":ref.loc[X_test.index]['Close Price'].values.tolist()})\n",
    "    linres.update({\"date\":ref.loc[X_test.index]['Date'].apply(lambda row : row.strftime('%Y-%m-%d')).values.tolist()})\n",
    "    return linres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5bb5706-9b3c-4eac-b5ac-56fd924a943c",
    "_uuid": "5f286a9c-9fce-4558-b016-fc0b89681213",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "necessary_columns = [\"Date\",\"Close Price\",\"Previous 360 days UB\",\"Min Inc % in 180 days\",\"Next 60 days LB\",\"Previous 720 days UB\",\"No. of Trades GR\",\"CP % LV 180 days\",\"Max Inc % in 180 days\",\"Next 1080 days LB\",\"CP % BA 180 days\",\"Next Day Low Price GR\",\"Max Dec % in 90 days\",\"Expenditure GR\",\"CP % HV 90 days\",\"Min Dec % in 365 days\",\"Max Dec % in 365 days\",\"CP % HV 7 days\",\"CP % BA 7 days\",\"Avg Inc % in 365 days\",\"Min Inc % in 90 days\",\"Avg Inc % in 180 days\",\"Total Turnover (Rs.) GR\",\"Low Price GR\",\"Previous 1080 days UB\",\"CP % HV 180 days\",\"Next 180 days UB\",\"No.of Shares GR\",\"Previous 60 days UB\",\"CP % BA 90 days\",\"Avg Inc % in 90 days\",\"Sequential Increase %\",\"WAP GR\",\"CP % BA 30 days\",\"Avg Dec % in 180 days\",\"Previous 720 days LB\",\"EPS GR\",\"Deliverable Quantity GR\",\"Next 360 days UB\",\"CP % HV 365 days\",\"Spread Close-Open GR\",\"Min Dec % in 180 days\",\"Next 30 days LB\",\"Sequential Increase\",\"Previous 360 days LB\",\"Alpha GR\",\"CP % LV 365 days\",\"Dividend Value GR\",\"Sequential Decrease\",\"Next 360 days LB\",\"Avg Dec % in 365 days\",\"Net Profit GR\",\"CP % LV 7 days\",\"CP % HV 30 days\",\"% Deli. Qty to Traded Qty GR\",\"Min Inc % in 365 days\",\"Sequential Decrease %\",\"Beta GR\",\"Next 30 days UB\",\"High Price GR\",\"Spread High-Low GR\",\"Income GR\",\"Max Dec % in 180 days\",\"Previous 30 days UB\",\"Next 90 days UB\",\"Next 90 days LB\",\"Next 1080 days UB\",\"Open Price GR\",\"Next 720 days LB\",\"Max Inc % in 365 days\",\"Previous 90 days LB\",\"Previous 90 days UB\",\"Next 60 days UB\",\"Avg Dec % in 90 days\",\"Previous 30 days LB\",\"Previous 1080 days LB\",\"Next Day Open Price GR\",\"Next Day High Price GR\",\"CP % BA 365 days\",\"Max Inc % in 90 days\",\"Revenue GR\",\"CP % LV 30 days\",\"Min Dec % in 90 days\",\"Next 180 days LB\",\"Previous 180 days LB\",\"Close Price GR\",\"CP % LV 90 days\",\"Previous 60 days LB\",\"Previous 180 days UB\",\"Next 720 days UB\",\"Next Day Close Price GR\"]\n",
    "columns_to_predict = ['Next 30 days LB','Next 30 days UB','Next 60 days LB','Next 60 days UB','Next 90 days LB','Next 90 days UB','Next 180 days LB','Next 180 days UB','Next 360 days LB','Next 360 days UB','Next 720 days LB','Next 720 days UB','Next 1080 days LB','Next 1080 days UB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5fe471ca-14c5-4ab6-bd79-ed14900341f6",
    "_uuid": "e210eba8-95b3-4886-a3d5-cde5407b9bbd",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv(\"https://raw.githubusercontent.com/saikr789/stock-analysis-tool-1011/master/Data/SP500companies.csv\")\n",
    "sp500companies = sp500['Security Code'].values.tolist()\n",
    "sp500companies.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "87d9d93a-f3a8-4ca9-b4fa-04b0bc664522",
    "_uuid": "f9795f79-6ab6-4887-a96b-eb8b89d4d092",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_companies_lb(security_code):\n",
    "    try:\n",
    "        print(security_code)\n",
    "        security_code = str(security_code)\n",
    "        df = pd.read_csv(\"../input/sp500-dataset/\"+\"gr\"+security_code+\".csv\")\n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[necessary_columns]\n",
    "        col = 'Next 30 days LB'\n",
    "        result = run_models(df,col)\n",
    "        result.update({\"company\":security_code})\n",
    "        return result\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def run_companies_ub(security_code):\n",
    "    try:\n",
    "        print(security_code)\n",
    "        security_code = str(security_code)\n",
    "        df = pd.read_csv(\"../input/sp500-dataset/\"+\"gr\"+security_code+\".csv\")\n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df[necessary_columns]\n",
    "        col = 'Next 30 days UB'\n",
    "        result = run_models(df,col)\n",
    "        result.update({\"company\":security_code})\n",
    "        return result\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d4c331d-d088-4d37-af74-7c415cfa4e32",
    "_uuid": "59ee09ed-b109-42f2-a293-0627244ee4cf",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pool = ThreadPool(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddd4f9a5-5fd0-44da-ab7c-3b07539fd00e",
    "_uuid": "9a18cd43-f2a0-418b-b856-6d29e57aa860",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    lbresult = pool.map(run_companies_lb,sp500companies)\n",
    "    pd.DataFrame(lbresult).to_csv(\"next_30_days_lb.csv\",index=None)\n",
    "    ubresult = pool.map(run_companies_ub,sp500companies)\n",
    "    pd.DataFrame(ubresult).to_csv(\"next_30_days_ub.csv\",index=None)\n",
    "    result = lbresult + ubresult\n",
    "    resultdf = pd.DataFrame(result)\n",
    "    resultdf.to_csv(\"next_30_days.csv\",index=None)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db2b384f-3c34-437a-a489-7ba3af17af9b",
    "_uuid": "1169adca-e4ff-4651-84d2-34eb1eb8dc8a",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for security_code in sp500companies:\n",
    "#     try:\n",
    "#         print(security_code)\n",
    "#         security_code = str(security_code)\n",
    "#         df = pd.read_csv(\"../input/sp500-dataset/\"+\"gr\"+security_code+\".csv\")\n",
    "#         df = df.iloc[::-1].reset_index(drop=True)\n",
    "#         df['Date'] = pd.to_datetime(df['Date'])\n",
    "#         df = df[necessary_columns]\n",
    "#         pool = ThreadPool(multiprocessing.cpu_count())\n",
    "#         combs = list(zip([df]*len(columns_to_predict),columns_to_predict))\n",
    "#         result = pool.starmap(run_models,combs)\n",
    "#         resultdf = pd.DataFrame(result)\n",
    "#         resultdf.to_csv(name[2:],index=None)\n",
    "#     except:\n",
    "#         traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
