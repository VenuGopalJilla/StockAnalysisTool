{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install neupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polyphonic-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "previous-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expensive-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neupy import algorithms\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-genetics",
   "metadata": {},
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identical-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(data,null_threshold):\n",
    "    \"\"\"\n",
    "    Drops Date and Unix Date columns from the data.\n",
    "    Drops the columns which has null values more than specified null_threshold.\n",
    "    Replaces infinite values with NAN.\n",
    "    Drops the rows which has null values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    null_threshold : numeric\n",
    "        numeric value describing the amount of null values that can be present.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    \"\"\"\n",
    "    \n",
    "    data.drop(columns=['Unix Date','Date'],axis=1,inplace=True)\n",
    "    total = data.shape[0]\n",
    "    for col in data.columns:\n",
    "        if null_threshold * total / 100 < data[col].isnull().sum():\n",
    "            data.drop(columns=[col],axis=1,inplace=True)\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data = data.apply(pd.to_numeric,errors='coerce')\n",
    "    data.dropna(axis=0,inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-mixture",
   "metadata": {},
   "source": [
    "# Removing columns based on the dependent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependent_column(data,column):\n",
    "    \"\"\"\n",
    "    Removes all the Next Day columns.\n",
    "    Removes all the non Growth Rate Columns (GR)\n",
    "    add the predictor column to list of columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataframe\n",
    "\n",
    "    column : string\n",
    "        name of the predictor column \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dataframe\n",
    "        an updated dataframe after performing all the opertaions.\n",
    "    column : string\n",
    "        name of the predictor column\n",
    "    \"\"\"\n",
    "    cols = [col for col in data.columns if \"next\" not in col.lower() and col.lower().endswith(\"gr\")]\n",
    "    cols.append(column)\n",
    "    data = data[cols]\n",
    "    return (data,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-click",
   "metadata": {},
   "source": [
    "# Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sudden-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, target, significance_level=0.05):\n",
    "    initial_features = data.columns.tolist()\n",
    "    best_features = []\n",
    "    while (len(initial_features)>0):\n",
    "        remaining_features = list(set(initial_features)-set(best_features))\n",
    "        new_pval = pd.Series(index=remaining_features)\n",
    "        for new_column in remaining_features:\n",
    "            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]]).astype(float)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        min_p_value = new_pval.min()\n",
    "        if(min_p_value<significance_level):\n",
    "            best_features.append(new_pval.idxmin())\n",
    "        else:\n",
    "            break\n",
    "    return best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weekly-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target,significance_level = 0.05):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features]).astype(float)\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= significance_level):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-maldives",
   "metadata": {},
   "source": [
    "# GNN and its best parameters function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sufficient-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(1e-1, 1, 1e-2)\n",
    "# np.linspace(0, 1, 11)\n",
    "# a = np.array(1)\n",
    "# type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "gorgeous-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParameters(X,Y,std):\n",
    "#     model = RandomizedSearchCV(algorithms.GRNN(std=std, verbose=False), param_distributions={'std': np.arange(1e-2, 1, 1e-3)}, scoring='neg_mean_squared_error',)\n",
    "#     model = GridSearchCV(algorithms.GRNN(std = 0.1, verbose=False), param_grid={'std': std}, scoring='neg_mean_squared_error',verbose = 2)\n",
    "    model = GridSearchCV(algorithms.GRNN(std = std, verbose = False), param_grid={'std': np.arange(1e-2, 1, 1e-3)}, scoring='neg_mean_squared_error',verbose = 1)\n",
    "#     model = GridSearchCV(algorithms.GRNN(std = std, verbose = False), param_grid={'std': np.arange(1e-1, 1, 1e-2)}, scoring='neg_mean_squared_error',verbose = 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behind-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generalized_neural_network(X,Y,std=0.1):\n",
    "#     best = bestParameters(X,Y,std)\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(preprocessing.minmax_scale(X), preprocessing.minmax_scale(Y), test_size=0.3, random_state=0)\n",
    "#     model = algorithms.GRNN(std=best['std'])\n",
    "#     model.train(x_train,y_train)\n",
    "#     y_pred = model.predict(x_test)\n",
    "#     rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "#     mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "#     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "#     r2 = metrics.r2_score(y_test, y_pred)\n",
    "#     c = 0\n",
    "#     for a,b in zip(y_test, y_pred):\n",
    "#         if a*b >= 0:\n",
    "#             c += 1\n",
    "#     direction = c/len(y_test)\n",
    "#     myres =  {\"RMSE\":rmse,\"MAE\":mae,\"MSE\":mse,\"rsquared_adj\":r2,\"std\":std, \"best-std\":best['std'],\"Percentage\":direction}\n",
    "#     print(\"done\")\n",
    "#     return myres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funny-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_neural_network(X,Y,name, method, std):\n",
    "    best = bestParameters(X,Y,std)\n",
    "    print(best)\n",
    "    \n",
    "    # preprocessing.minmax_scale(X) is done to avoid Nan values in the predicted values \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    model = algorithms.GRNN(std=best['std'])\n",
    "    model.train(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "#     print(list(zip(y_test, y_pred)))\n",
    "    pred_actual = pd.DataFrame(list(zip(y_pred, y_test)), \n",
    "                   columns =['Predicted Values', 'Actual Values'])\n",
    "#     pred_actual['Predicted Values'] = pred_actual['Predicted Values'].astype(str)\n",
    "#     pred_actual['Actual Values'] = pred_actual['Actual Values'].astype(str)\n",
    "#     print(list(zip(pred_actual['Predicted Values'], pred_actual['Actual Values'])))\n",
    "\n",
    "#     preds = []\n",
    "#     for i in y_pred:\n",
    "#         preds.append(i[0])\n",
    "\n",
    "#     pred_actual = pd.DataFrame()\n",
    "#     pred_actual['Predicted Values'] = preds\n",
    "#     pred_actual['Actual Values'] = y_test\n",
    "    pred_actual.to_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models_Results\\\\\" + name[2:8] + \"_GRNN_FI_\" + method + \"_std_\" + str(round(best['std'], 6)) +\".csv\" , index=False) \n",
    "    \n",
    "    y_pred = np.nan_to_num(y_pred)\n",
    "    \n",
    "    rmse = sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    c = 0\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    for a,b in zip(y_test, y_pred):\n",
    "        if (a > 0 and b[0] > 0) or (a < 0 and b[0] < 0):\n",
    "            print(a, b[0], a * b[0])\n",
    "            c += 1\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "#     print(\"Direction : \")\n",
    "    print(c, len(y_test), c / len(y_test))\n",
    "    \n",
    "    direction = c / len(y_test)\n",
    "    myres =  {\"RMSE\":rmse,\"MAE\":mae,\"MSE\":mse,\"rsquared_adj\":r2,\"std\":std, \"best-std\":best['std'],\"Percentage\":direction}\n",
    "#     print(\"done\")\n",
    "    return myres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-earthquake",
   "metadata": {},
   "source": [
    "# Finding results from each set of important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intense-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GNN(df, column, method, name, results):\n",
    "    print(\"GRNN Model fitted using columns obtained from feature importance using \" + method + \" : \")\n",
    "    X = df[df.columns[:-1]]\n",
    "    Y = df[column].values\n",
    "    \n",
    "    std = 0.1\n",
    "    model_result = generalized_neural_network(X, Y, name, method, std)\n",
    "        \n",
    "    \n",
    "    results[\"GRNN_FI_\" + method + \"_stds_\" + str(round(model_result['best-std'], 6))] = model_result[\"Percentage\"]\n",
    "    \n",
    "    create_pretty_table(name , \"GRNN\", method + \"-\" + str(round(round(model_result['best-std'], 6))), model_result)\n",
    "    print(\"Maximum percentage of correct direction : \", model_result[\"Percentage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "robust-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_GNN(df, column, method, name, results):\n",
    "#     print(\"GRNN Model fitted using columns obtained from feature importance using \" + method + \" : \")\n",
    "#     X = df[df.columns[:-1]]\n",
    "#     Y = df[column].values\n",
    "    \n",
    "#     data = list()\n",
    "#     stds = np.linspace(0,1,11)\n",
    "#     arguments = list()\n",
    "#     max_percentage = 0\n",
    "#     for s in stds:\n",
    "#         data = [X,Y,s]\n",
    "#         arguments.append(data)\n",
    "#         model_result = generalized_neural_network(X, Y, name, method, s)\n",
    "#         if (max_percentage < model_result[\"Percentage\"]):\n",
    "#             max_percentage = model_result[\"Percentage\"]\n",
    "# #     threads = ThreadPool(4)\n",
    "# #     model_result = threads.starmap(generalized_neural_network,arguments)\n",
    "    \n",
    "# #         print(model_result)\n",
    "    \n",
    "# #         print(\"Percentage of correct direction : \", model_result[\"Percentage\"])\n",
    "        \n",
    "    \n",
    "#         results[\"GRNN_Regression_FI_\" + method + \"_stds_\" + str(round(s, 2))] = model_result[\"Percentage\"]\n",
    "    \n",
    "#         create_pretty_table(name , \"GRNN_Regression\", method + \"-\" + str(round(s, 2)), model_result)\n",
    "#     print(\"Maximum percentage of correct direction : \", max_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "animal-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_ForwardSelection(df1, name, column, results):\n",
    "    print(\"Features Importance using Forward Selection Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"ForwardSelection\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    forward_features = forward_selection(X,Y)\n",
    "    print(\"Features obtained from Forward Selection method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(forward_features)\n",
    "    if (len(forward_features) != 0):\n",
    "        forward_features.append(column)\n",
    "        df_fs = df1[forward_features]\n",
    "        fit_GNN(df_fs, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tough-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_BackwardElimination(df1, name, column, results):\n",
    "    print(\"Features Importance using Backward Elimination Method\")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"BackwardElimination\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    backward_features = backward_elimination(X,Y)\n",
    "    print(\"Features obtained from Backward Elimination method : \") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(backward_features)\n",
    "    if (len(backward_features) != 0):\n",
    "        backward_features.append(column)\n",
    "        df_be = df1[backward_features]\n",
    "        fit_GNN(df_be, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "falling-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_FI_AllFeatures(df1, name, column, results):\n",
    "    print(\"All Features are considered : \")\n",
    "    print(\"*****************************************************************************************\")\n",
    "    method = \"AllFeaturesConsideration\"\n",
    "    X = df1[df1.columns[:-1]]\n",
    "    Y = df1[column].values\n",
    "    all_features = list(X.columns)\n",
    "    print(\"All Features are --->>\") \n",
    "    print(\"--------------------------------------\")\n",
    "    print(all_features)\n",
    "    if (len(all_features) != 0):\n",
    "        all_features.append(column)\n",
    "        df_all = df1[all_features]\n",
    "        fit_GNN(df_all, column, method, name, results)\n",
    "    print(\"*****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lonely-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_from_each_set(data, name, final_df):\n",
    "    df = pre_process_data(data, 60)\n",
    "    column = \"Next Day Close Price GR\"\n",
    "    (df1, column) = dependent_column(df, column)\n",
    "    results = {}\n",
    "    get_results_from_FI_ForwardSelection(df1, name, column, results)\n",
    "    get_results_from_FI_BackwardElimination(df1, name, column, results)\n",
    "    get_results_from_FI_AllFeatures(df1, name, column, results)\n",
    "    sorted_results = sorted(results.items(), key=lambda item: item[1])\n",
    "    max_row = {'Company' : name[2 : 8] + \"-\" + companies[name[2 : 8]], 'Model' : 'GRNN', 'Method' : sorted_results[-1][0], 'Percentage' : sorted_results[-1][1]}\n",
    "    final_df = final_df.append(max_row, ignore_index = True)\n",
    "    print(\"Maximum correct direction values are obtained for {} with a percentage of {}.\".format(sorted_results[-1][0], sorted_results[-1][1]))\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-substitute",
   "metadata": {},
   "source": [
    "# Process of getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "corporate-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretty_table(name, model, method, result):\n",
    "    values = [name[2 : 8 ] + \"-\" + companies[name[2 : 8]], method] + [round(v, 6) if (isinstance(v, float)) else v for k,v in result.items()]\n",
    "    tables[model].add_row(values)\n",
    "    tables[model].title = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lined-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =['Company','Method', 'RMSE','MAE','MSE','rsquared_adj','std','best-std','Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "animal-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = {\"500112\" : \"SBIN\" ,\n",
    "\"500325\" : \"RELIANCE INDUSTRIES LTD\",\n",
    "\"532540\" : \"TATA CONSULTANCY SERVICES LTD\" ,\n",
    "\"500209\" : \"INFOSYS LTD\", \n",
    "\"532174\" : \"ICICI BANK LTD\", \n",
    "\"507685\" : \"WIPRO LTD\", \n",
    "\"530965\" : \"INDIAN OIL CORPORATION LTD\", \n",
    "\"500182\" : \"HERO MOTOCORP LTD\", \n",
    "\"532210\" : \"CITY UNION BANK LTD\", \n",
    "\"500180\" : \"HDFC Bank Ltd\",\n",
    "\"500680\" : \"PFIZER LTD\", \n",
    "\"506395\" : \"COROMANDEL iNTERNATIONAL LTD\",\n",
    "\"500770\" : \"TATA CHEMICALS LTD\", \n",
    "\"500085\" : \"CHAMBAL FERTILISERS & CHEMICALS LTD\", \n",
    "\"501425\" : \"BOMBAY BURMAH TRADING CORP.LTD\", \n",
    "\"532899\" : \"KAVERI SEED COMPANY LTD\", \n",
    "\"537291\" : \"NATH BIO-GENES (INDIA) LTD\", \n",
    "\"500790\" : \"NESTLE INDIA LTD\", \n",
    "\"500825\" : \"BRITANNIA INDUSTRIES LTD\", \n",
    "\"533155\" : \"JUBILANT FOODWORKS LTD\", \n",
    "\"533287\" : \"ZEE LEARN LTD\", \n",
    "\"533260\" : \"CAREER POINT LTD\", \n",
    "\"539921\" : \"SHANTI EDUCATIONAL INITIATIVES LTD\", \n",
    "\"542602\" : \"EMBASSY OFFICE PARKS REIT\", \n",
    "\"543217\" : \"MINDSPACE BUSINESS PARKS REIT\", \n",
    "\"543261\" : \"BROOKFIELD INDIA REAL ESTATE TRUST REIT\", \n",
    "\"532538\" : \"ULTRATECH CEMENT LTD\", \n",
    "\"500387\" : \"SHREE CEMENT LTD\", \n",
    "\"500425\" : \"AMBUJA CEMENTS LTD\", \n",
    "\"532689\" : \"PVR LTD\", \n",
    "\"532706\" : \"INOX LEISURE LTD\", \n",
    "\"532163\" : \"SAREGAMA INDIA LTD\", \n",
    "\"524715\" : \"SUN PHARMACEUTICAL INDUSTRIES LTD\", \n",
    "\"532488\" : \"DIVI'S LABORATORIES LTD\",\n",
    "\"500124\" : \"DR.REDDY'S LABORATORIES LTD\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "technical-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"GRNN\"]\n",
    "tables = {model:PrettyTable() for model in models}\n",
    "for name,table in tables.items():\n",
    "    table.field_names = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "forced-newport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Model</th>\n",
       "      <th>Method</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>KNN-Regression</td>\n",
       "      <td>KNN_Regression_FI_BackwardElimination_</td>\n",
       "      <td>0.540342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>RNN-Regression</td>\n",
       "      <td>RNN_Regression_FI_AllFeaturesConsideration</td>\n",
       "      <td>0.513447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>RidgeFIFValue1</td>\n",
       "      <td>0.506112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>LinearFIBackwardElimination</td>\n",
       "      <td>0.501222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500085-CHAMBAL FERTILISERS &amp; CHEMICALS LTD</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>LassoFIFValue10</td>\n",
       "      <td>0.497555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>LinearFICoefficients0.1</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>RidgeFICoefficients0.1</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>KNN-Regression</td>\n",
       "      <td>KNN_Regression_FI_AllFeaturesConsideration_</td>\n",
       "      <td>0.530769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>RNN-Regression</td>\n",
       "      <td>RNN_Regression_FI_BackwardElimination</td>\n",
       "      <td>0.507692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>542602-EMBASSY OFFICE PARKS REIT</td>\n",
       "      <td>SVR</td>\n",
       "      <td>SVR_FI_FValue_1</td>\n",
       "      <td>0.484615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company              Model  \\\n",
       "0    500085-CHAMBAL FERTILISERS & CHEMICALS LTD     KNN-Regression   \n",
       "1    500085-CHAMBAL FERTILISERS & CHEMICALS LTD     RNN-Regression   \n",
       "2    500085-CHAMBAL FERTILISERS & CHEMICALS LTD   Ridge Regression   \n",
       "3    500085-CHAMBAL FERTILISERS & CHEMICALS LTD  Linear Regression   \n",
       "4    500085-CHAMBAL FERTILISERS & CHEMICALS LTD   Lasso Regression   \n",
       "..                                          ...                ...   \n",
       "219            542602-EMBASSY OFFICE PARKS REIT  Linear Regression   \n",
       "220            542602-EMBASSY OFFICE PARKS REIT   Ridge Regression   \n",
       "221            542602-EMBASSY OFFICE PARKS REIT     KNN-Regression   \n",
       "222            542602-EMBASSY OFFICE PARKS REIT     RNN-Regression   \n",
       "223            542602-EMBASSY OFFICE PARKS REIT                SVR   \n",
       "\n",
       "                                          Method  Percentage  \n",
       "0         KNN_Regression_FI_BackwardElimination_    0.540342  \n",
       "1     RNN_Regression_FI_AllFeaturesConsideration    0.513447  \n",
       "2                                 RidgeFIFValue1    0.506112  \n",
       "3                    LinearFIBackwardElimination    0.501222  \n",
       "4                                LassoFIFValue10    0.497555  \n",
       "..                                           ...         ...  \n",
       "219                      LinearFICoefficients0.1    0.538462  \n",
       "220                       RidgeFICoefficients0.1    0.538462  \n",
       "221  KNN_Regression_FI_AllFeaturesConsideration_    0.530769  \n",
       "222        RNN_Regression_FI_BackwardElimination    0.507692  \n",
       "223                              SVR_FI_FValue_1    0.484615  \n",
       "\n",
       "[224 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv(\"C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models_Results\\\\df_Final_Results.csv\")\n",
    "# final_df.drop('Unnamed: 0', inplace = True, axis = 'columns')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fitting-chicago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-culture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For stock :  500085\n",
      "#################################################################################################################\n",
      "Features Importance using Forward Selection Method\n",
      "*****************************************************************************************\n",
      "Features obtained from Forward Selection method : \n",
      "--------------------------------------\n",
      "['Beta GR']\n",
      "GRNN Model fitted using columns obtained from feature importance using ForwardSelection : \n",
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n",
      "{'std': 0.30599999999999977}\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "0 818 0.0\n",
      "Maximum percentage of correct direction :  0.0\n",
      "*****************************************************************************************\n",
      "Features Importance using Backward Elimination Method\n",
      "*****************************************************************************************\n",
      "Features obtained from Backward Elimination method : \n",
      "--------------------------------------\n",
      "['Beta GR']\n",
      "GRNN Model fitted using columns obtained from feature importance using BackwardElimination : \n",
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n",
      "{'std': 0.30599999999999977}\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "0 818 0.0\n",
      "Maximum percentage of correct direction :  0.0\n",
      "*****************************************************************************************\n",
      "All Features are considered : \n",
      "*****************************************************************************************\n",
      "All Features are --->>\n",
      "--------------------------------------\n",
      "['Open Price GR', 'High Price GR', 'Low Price GR', 'Close Price GR', 'WAP GR', 'No.of Shares GR', 'No. of Trades GR', 'Total Turnover (Rs.) GR', 'Deliverable Quantity GR', '% Deli. Qty to Traded Qty GR', 'Spread High-Low GR', 'Spread Close-Open GR', 'Alpha GR', 'Beta GR', 'Revenue GR', 'Dividend Value GR', 'Income GR', 'Expenditure GR', 'Net Profit GR', 'EPS GR']\n",
      "GRNN Model fitted using columns obtained from feature importance using AllFeaturesConsideration : \n",
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for filename in os.listdir(os.path.join(path,\"Data/Stock\")):\n",
    "    if filename.startswith(\"gr500085\"):\n",
    "        df_gnn = pd.read_csv(os.path.join(path,\"Data\\Stock\\\\\" + filename))\n",
    "        name = os.path.join(path, \"Data\\Stock\\\\\" + filename).split(\"\\\\\")[-1]\n",
    "        stock = name[2 : 8]\n",
    "        fd_df = pd.DataFrame(columns = final_df.columns)\n",
    "        print(\"For stock : \", stock)\n",
    "        print(\"#################################################################################################################\")\n",
    "        f_df = get_results_from_each_set(df_gnn, name, fd_df)\n",
    "        final_df = final_df.append(f_df, ignore_index = True)\n",
    "        print(\"#################################################################################################################\")\n",
    "        break\n",
    "        \n",
    "# final_df = final_df.sort_values(by = ['Company', 'Percentage'], ascending = [True, False])\n",
    "# final_df.to_csv('C:\\\\Users\\\\venu\\\\Desktop\\\\Stock Market Analysis\\\\Data\\\\Models_Results\\\\df_Final_Results_GRNN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         filepath = os.path.join(dirname, filename)\n",
    "#         df = pd.read_csv(filepath)\n",
    "#         df = pre_process_data(df,60)\n",
    "#         column = \"Next Day Close Price GR\"\n",
    "#         (df,column) = dependent_column(df,column)\n",
    "#         X = df.drop(columns=[column])\n",
    "#         Y = df[column]\n",
    "        \n",
    "#         resultdf = pd.DataFrame(result)\n",
    "#         resultdf.to_csv(os.path.join(os.getcwd(),str(filename[2:8])+\"_gnn\"+\".csv\"),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,table in tables.items():\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-toddler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
